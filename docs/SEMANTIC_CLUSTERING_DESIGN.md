# Semantic Clustering â€” Domain Discovery Through Code Intelligence

> **Version**: 1.0  
> **Status**: Design Draft  
> **Created**: February 6, 2026  
> **Purpose**: Automatic domain boundary discovery using semantic analysis of code structure, naming, and relationships

---

## Executive Summary

Semantic Clustering extends LFCA beyond temporal coupling analysis to discover **business domains** and **logical boundaries** through deep semantic analysis of code. Unlike commit-based coupling (which answers "what changes together?"), semantic clustering answers:

- **"What belongs together?"** â€” Files with similar purpose/domain
- **"What domains exist in this codebase?"** â€” Automatic bounded context discovery
- **"Which domain does this class serve?"** â€” Entity-to-domain mapping

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEMANTIC CLUSTERING OVERVIEW                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚   Codebase    â”‚â”€â”€â”€â”€â–¶â”‚   Semantic    â”‚â”€â”€â”€â”€â–¶â”‚    Domain     â”‚            â”‚
â”‚   â”‚   Analysis    â”‚     â”‚   Embedding   â”‚     â”‚   Clusters    â”‚            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚          â”‚                     â”‚                     â”‚                      â”‚
â”‚          â–¼                     â–¼                     â–¼                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚   â”‚ â€¢ AST Parsing â”‚     â”‚ â€¢ Code2Vec    â”‚     â”‚ â€¢ Payment     â”‚            â”‚
â”‚   â”‚ â€¢ Token Filterâ”‚     â”‚ â€¢ TF-IDF      â”‚     â”‚ â€¢ Auth        â”‚            â”‚
â”‚   â”‚ â€¢ Name Extractâ”‚     â”‚ â€¢ BERT Embeds â”‚     â”‚ â€¢ Inventory   â”‚            â”‚
â”‚   â”‚ â€¢ Type Analyzeâ”‚     â”‚ â€¢ Graph Embedsâ”‚     â”‚ â€¢ Reporting   â”‚            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Table of Contents

1. [Vision & Goals](#1-vision--goals)
2. [Core Concepts](#2-core-concepts)
3. [Feature Specifications](#3-feature-specifications)
4. [Algorithms & Techniques](#4-algorithms--techniques)
5. [Technology Choices](#5-technology-choices)
6. [Architecture](#6-architecture)
7. [API Design](#7-api-design)
8. [Data Models](#8-data-models)
9. [Implementation Roadmap](#9-implementation-roadmap)
10. [Success Metrics](#10-success-metrics)

---

## 1. Vision & Goals

### 1.1 Vision Statement

Transform any codebase into a **discoverable domain map** by analyzing code semantics â€” class names, method signatures, comments, variable names, and structural patterns â€” to automatically identify business domains and their boundaries.

### 1.2 Primary Goals

| Goal | Description | Value |
|------|-------------|-------|
| **Domain Discovery** | Automatically identify business domains (Payment, Auth, Inventory...) | Understand legacy codebases |
| **Entity Classification** | For any class, know which domain(s) it belongs to | Navigate large codebases |
| **Similarity Grouping** | Group semantically similar classes/files | Identify duplication, cohesion |
| **Boundary Detection** | Find where one domain ends and another begins | Architecture documentation |
| **Tech Token Filtering** | Exclude framework noise (.NET, Spring, React tokens) | Focus on business semantics |

### 1.3 What This Feature Enables

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USE CASES ENABLED                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ðŸ‘¤ FOR DEVELOPERS                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚  â€¢ "Show me all files related to payment processing"                        â”‚
â”‚  â€¢ "Which domain should this new feature go into?"                          â”‚
â”‚  â€¢ "Find similar code to what I'm writing"                                  â”‚
â”‚                                                                             â”‚
â”‚  ðŸ—ï¸ FOR ARCHITECTS                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚  â€¢ "What are the natural bounded contexts in our monolith?"                 â”‚
â”‚  â€¢ "Which domains have the most cross-cutting concerns?"                    â”‚
â”‚  â€¢ "Are there files that span multiple domains (god classes)?"              â”‚
â”‚                                                                             â”‚
â”‚  ðŸ“Š FOR TECH LEADS                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                         â”‚
â”‚  â€¢ "Generate domain ownership assignments"                                  â”‚
â”‚  â€¢ "Identify microservice extraction candidates"                            â”‚
â”‚  â€¢ "Document implicit domain boundaries"                                    â”‚
â”‚                                                                             â”‚
â”‚  ðŸ”„ FOR MIGRATION PROJECTS                                                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚  â€¢ "Map legacy codebase domains before refactoring"                         â”‚
â”‚  â€¢ "Identify domain clusters for team assignment"                           â”‚
â”‚  â€¢ "Find hidden dependencies between domains"                               â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Core Concepts

### 2.1 Glossary

| Term | Definition |
|------|------------|
| **Semantic Token** | A meaningful identifier extracted from code (class name, method name, variable) |
| **Technical Token** | Framework/language-specific tokens to be filtered (DbContext, IRepository, useState) |
| **Domain Cluster** | A group of semantically related files/classes representing a business domain |
| **Embedding Vector** | Numerical representation of code semantics in high-dimensional space |
| **Domain Affinity** | Score indicating how strongly an entity belongs to a specific domain |
| **Bridge Entity** | A file/class that spans multiple domains (potential god class or shared utility) |
| **Semantic Signature** | The extracted semantic fingerprint of a code entity |

### 2.2 Semantic Analysis Dimensions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEMANTIC ANALYSIS DIMENSIONS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. LEXICAL (Names & Text)                                                  â”‚
â”‚     â”œâ”€â”€ Class names: PaymentProcessor, OrderService, UserRepository        â”‚
â”‚     â”œâ”€â”€ Method names: calculateTax, validatePayment, processRefund         â”‚
â”‚     â”œâ”€â”€ Variable names: orderTotal, customerId, invoiceNumber              â”‚
â”‚     â”œâ”€â”€ Comments & documentation strings                                   â”‚
â”‚     â””â”€â”€ String literals with business meaning                              â”‚
â”‚                                                                             â”‚
â”‚  2. STRUCTURAL (Relationships)                                              â”‚
â”‚     â”œâ”€â”€ Inheritance hierarchies                                            â”‚
â”‚     â”œâ”€â”€ Interface implementations                                          â”‚
â”‚     â”œâ”€â”€ Method call graphs                                                 â”‚
â”‚     â”œâ”€â”€ Type dependencies (parameters, return types)                       â”‚
â”‚     â””â”€â”€ Namespace/package organization                                     â”‚
â”‚                                                                             â”‚
â”‚  3. BEHAVIORAL (Patterns)                                                   â”‚
â”‚     â”œâ”€â”€ Design pattern detection (Repository, Factory, Service...)         â”‚
â”‚     â”œâ”€â”€ CRUD operation patterns                                            â”‚
â”‚     â”œâ”€â”€ Event handlers and callbacks                                       â”‚
â”‚     â””â”€â”€ Data flow patterns                                                 â”‚
â”‚                                                                             â”‚
â”‚  4. CONTEXTUAL (Position)                                                   â”‚
â”‚     â”œâ”€â”€ Directory/folder structure                                         â”‚
â”‚     â”œâ”€â”€ Module organization                                                â”‚
â”‚     â”œâ”€â”€ Test file associations                                             â”‚
â”‚     â””â”€â”€ Configuration file relationships                                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 Technical Token Filtering

Technical tokens are framework/language-specific identifiers that add noise to domain analysis. The system maintains **technology-specific stopword lists**.

```python
# Example: .NET Technical Tokens
DOTNET_TECHNICAL_TOKENS = {
    # Entity Framework
    "DbContext", "DbSet", "IQueryable", "EntityTypeConfiguration",
    "OnModelCreating", "HasKey", "HasIndex", "ToTable",
    
    # ASP.NET
    "Controller", "ApiController", "ActionResult", "IActionResult",
    "HttpGet", "HttpPost", "HttpPut", "HttpDelete", "Route",
    "Authorize", "AllowAnonymous", "FromBody", "FromQuery",
    
    # Dependency Injection
    "IServiceCollection", "IServiceProvider", "AddScoped", 
    "AddSingleton", "AddTransient", "IOptions",
    
    # Common Patterns
    "Repository", "UnitOfWork", "Specification", "Handler",
    "Command", "Query", "Event", "Dto", "ViewModel",
    
    # Generic Types
    "IEnumerable", "ICollection", "IList", "Task", "Async",
    "CancellationToken", "ILogger", "IConfiguration"
}

# Example: React/TypeScript Technical Tokens
REACT_TECHNICAL_TOKENS = {
    # React Core
    "useState", "useEffect", "useCallback", "useMemo", "useRef",
    "useContext", "useReducer", "Component", "PureComponent",
    
    # Lifecycle
    "componentDidMount", "componentWillUnmount", "render",
    "getDerivedStateFromProps", "shouldComponentUpdate",
    
    # Patterns
    "Provider", "Consumer", "Context", "Suspense", "ErrorBoundary",
    "HOC", "withRouter", "connect", "dispatch", "reducer",
    
    # TypeScript
    "interface", "type", "Props", "State", "FC", "ReactNode"
}
```

---

## 3. Feature Specifications

### 3.1 Feature 1: Domain Discovery

**Description**: Automatically analyze a codebase and discover distinct business domains.

```
INPUT:  Repository path + configuration
OUTPUT: List of discovered domains with:
        - Domain name (auto-generated or suggested)
        - Member files/classes
        - Domain keywords (extracted concepts)
        - Cohesion score
        - Inter-domain coupling map
```

**Workflow**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. Parse  â”‚â”€â”€â”€â”€â–¶â”‚  2. Extract â”‚â”€â”€â”€â”€â–¶â”‚  3. Embed   â”‚â”€â”€â”€â”€â–¶â”‚  4. Cluster â”‚
â”‚   Codebase  â”‚     â”‚   Tokens    â”‚     â”‚   Vectors   â”‚     â”‚   Domains   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                                       â”‚
                           â–¼                                       â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  5. Filter  â”‚                         â”‚  6. Name    â”‚
                    â”‚  Tech Tokensâ”‚                         â”‚  Domains    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Feature 2: Entity-to-Domain Classification

**Description**: Given any class/file, determine which domain(s) it belongs to.

```
INPUT:  File path (e.g., "src/services/PaymentProcessor.cs")
OUTPUT: Domain classification:
        - Primary domain: "Payment" (affinity: 0.87)
        - Secondary domains: ["Billing" (0.34), "Order" (0.21)]
        - Confidence: 0.92
        - Reasoning: "Contains payment-related terms, inherits from billing base..."
```

### 3.3 Feature 3: Similarity Search

**Description**: Find files/classes semantically similar to a given entity.

```
INPUT:  Source file path + similarity threshold
OUTPUT: Ranked list of similar entities:
        - Similar file path
        - Similarity score
        - Shared concepts
        - Relationship type (same domain, utility, test, etc.)
```

### 3.4 Feature 4: Domain Boundary Visualization

**Description**: Visual representation of domain clusters and their relationships.

```
OUTPUT: Interactive visualization showing:
        - Domain clusters as colored regions
        - Files as nodes within clusters
        - Inter-domain edges
        - Bridge files highlighted
        - Drill-down into individual domains
```

### 3.5 Feature 5: Technology-Aware Filtering

**Description**: Configure technology stack to exclude irrelevant tokens.

```
INPUT:  Technology profile configuration:
        - Primary: "dotnet"
        - Frameworks: ["entity-framework", "aspnet-core", "mediatr"]
        - Custom exclusions: ["MyCompanyBaseClass", "LegacyHelper"]
        
OUTPUT: Filtered semantic analysis focusing on business concepts
```

---

## 4. Algorithms & Techniques

### 4.1 Semantic Extraction Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEMANTIC EXTRACTION PIPELINE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STAGE 1: AST PARSING                                                 â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Source Code â”€â”€â–¶ Tree-Sitter â”€â”€â–¶ Syntax Tree â”€â”€â–¶ Typed Nodes        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Extractors per language:                                           â”‚   â”‚
â”‚  â”‚  â€¢ C#: Roslyn Analyzer (preferred) / Tree-sitter-c-sharp            â”‚   â”‚
â”‚  â”‚  â€¢ Python: ast module / Tree-sitter-python                          â”‚   â”‚
â”‚  â”‚  â€¢ TypeScript: TypeScript Compiler API / Tree-sitter-typescript     â”‚   â”‚
â”‚  â”‚  â€¢ Java: JavaParser / Tree-sitter-java                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                     â”‚
â”‚                                       â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STAGE 2: TOKEN EXTRACTION                                           â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Extract from:                                                      â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Class/Interface names                                          â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Method names + parameter names                                 â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Property/Field names + types                                   â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Local variable names                                           â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Comments (doc strings, inline)                                 â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ String literals (meaningful ones)                              â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Namespace/package names                                        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Apply: CamelCase/snake_case splitting, lowercasing                 â”‚   â”‚
â”‚  â”‚  Output: ["payment", "processor", "calculate", "tax", "invoice"...] â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                     â”‚
â”‚                                       â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STAGE 3: TOKEN FILTERING                                            â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Remove:                                                            â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Technology-specific tokens (configured per stack)              â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Generic programming terms ("get", "set", "create", "update")   â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Language keywords                                              â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Common stopwords                                               â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Single-character tokens                                        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Keep:                                                              â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Business domain terms                                          â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Entity names (nouns)                                           â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Action verbs with business meaning                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                     â”‚
â”‚                                       â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ STAGE 4: SEMANTIC ENRICHMENT                                        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Apply NLP techniques:                                              â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Lemmatization (invoices â†’ invoice)                             â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Synonym expansion (order â†” purchase)                           â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€ Compound term detection (credit_card â†’ credit-card)            â”‚   â”‚
â”‚  â”‚  â””â”€â”€ Abbreviation expansion (acct â†’ account)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Embedding Techniques

The system supports multiple embedding approaches, selected based on accuracy vs. performance tradeoffs:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       EMBEDDING TECHNIQUES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  TECHNIQUE 1: TF-IDF + LSA (Fast, Baseline)                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                â”‚
â”‚                                                                             â”‚
â”‚  1. Build corpus: Each file = document of extracted tokens                  â”‚
â”‚  2. Compute TF-IDF vectors with sublinear TF                               â”‚
â”‚  3. Apply Latent Semantic Analysis (LSA/SVD) for dimensionality reduction  â”‚
â”‚  4. Output: Dense vectors (100-300 dimensions)                             â”‚
â”‚                                                                             â”‚
â”‚  Pros: Fast, interpretable, no ML model needed                             â”‚
â”‚  Cons: Misses semantic relationships                                       â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                             â”‚
â”‚  TECHNIQUE 2: FastText / Word2Vec Aggregation (Balanced)                    â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                    â”‚
â”‚                                                                             â”‚
â”‚  1. Train domain-specific word embeddings on codebase                       â”‚
â”‚  2. For each file, average token embeddings (weighted by TF-IDF)           â”‚
â”‚  3. Optional: Smooth IDF for rare terms                                    â”‚
â”‚  4. Output: Dense vectors (100-300 dimensions)                             â”‚
â”‚                                                                             â”‚
â”‚  Pros: Captures semantic similarity (payment â‰ˆ billing)                    â”‚
â”‚  Cons: Requires training, misses context                                   â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                             â”‚
â”‚  TECHNIQUE 3: CodeBERT / GraphCodeBERT (High Accuracy)                      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                      â”‚
â”‚                                                                             â”‚
â”‚  1. Use pre-trained code understanding model                               â”‚
â”‚  2. Feed: [CLS] class_name methods properties [SEP]                        â”‚
â”‚  3. Extract [CLS] token embedding                                          â”‚
â”‚  4. Output: Dense vectors (768 dimensions)                                 â”‚
â”‚                                                                             â”‚
â”‚  Pros: State-of-the-art semantic understanding                             â”‚
â”‚  Cons: Slow, requires GPU for large codebases                              â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                             â”‚
â”‚  TECHNIQUE 4: Graph Neural Network Embeddings (Structural)                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                  â”‚
â”‚                                                                             â”‚
â”‚  1. Build code graph: files as nodes, dependencies as edges               â”‚
â”‚  2. Apply GraphSAGE / GAT to learn node embeddings                        â”‚
â”‚  3. Combine with lexical embeddings (multi-modal)                          â”‚
â”‚  4. Output: Dense vectors (128-256 dimensions)                             â”‚
â”‚                                                                             â”‚
â”‚  Pros: Captures structural patterns                                        â”‚
â”‚  Cons: Complex, requires graph construction                                â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                             â”‚
â”‚  TECHNIQUE 5: Hybrid Ensemble (Recommended)                                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                  â”‚
â”‚                                                                             â”‚
â”‚  1. Compute TF-IDF vectors for lexical baseline                            â”‚
â”‚  2. Compute Word2Vec aggregations for semantic similarity                  â”‚
â”‚  3. Compute graph embeddings for structural patterns                       â”‚
â”‚  4. Concatenate and project to final embedding space                       â”‚
â”‚  5. Output: Dense vectors (256 dimensions)                                 â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚ TF-IDF  â”‚   â”‚Word2Vec â”‚   â”‚  Graph  â”‚                                   â”‚
â”‚  â”‚ (100d)  â”‚   â”‚ (100d)  â”‚   â”‚  (64d)  â”‚                                   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                   â”‚
â”‚       â”‚             â”‚             â”‚                                         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚
â”‚                     â”‚                                                       â”‚
â”‚                     â–¼                                                       â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                             â”‚
â”‚            â”‚   Projection    â”‚                                             â”‚
â”‚            â”‚    (256d)       â”‚                                             â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Clustering Algorithms

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       CLUSTERING ALGORITHMS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ALGORITHM 1: HDBSCAN (Primary Choice)                                      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                       â”‚
â”‚                                                                             â”‚
â”‚  Hierarchical Density-Based Spatial Clustering                             â”‚
â”‚                                                                             â”‚
â”‚  Why HDBSCAN for Domain Discovery:                                         â”‚
â”‚  âœ“ No need to pre-specify number of clusters                               â”‚
â”‚  âœ“ Handles varying cluster densities (large vs small domains)              â”‚
â”‚  âœ“ Identifies outliers (utility classes, god classes)                      â”‚
â”‚  âœ“ Provides cluster hierarchy (domain â†’ subdomain)                         â”‚
â”‚  âœ“ Soft clustering available (for multi-domain entities)                   â”‚
â”‚                                                                             â”‚
â”‚  Parameters:                                                                â”‚
â”‚  â€¢ min_cluster_size: Minimum domain size (default: 5)                      â”‚
â”‚  â€¢ min_samples: Core point threshold (default: 3)                          â”‚
â”‚  â€¢ cluster_selection_epsilon: Merge threshold (default: 0.3)               â”‚
â”‚  â€¢ metric: cosine (for normalized embeddings)                              â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                             â”‚
â”‚  ALGORITHM 2: Agglomerative Hierarchical (Domain Hierarchy)                 â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                 â”‚
â”‚                                                                             â”‚
â”‚  For discovering domain hierarchies (Payment > Refund, Payment > Invoice)  â”‚
â”‚                                                                             â”‚
â”‚  Linkage methods:                                                          â”‚
â”‚  â€¢ Ward: Minimizes variance (good for balanced clusters)                   â”‚
â”‚  â€¢ Average: Uses mean distances (good for elongated clusters)              â”‚
â”‚  â€¢ Complete: Uses max distances (good for compact clusters)                â”‚
â”‚                                                                             â”‚
â”‚  Output: Dendrogram allowing exploration at different granularities        â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                             â”‚
â”‚  ALGORITHM 3: Spectral Clustering (Structure-Aware)                         â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                        â”‚
â”‚                                                                             â”‚
â”‚  For when structural relationships are important                           â”‚
â”‚                                                                             â”‚
â”‚  1. Build similarity graph from embeddings                                 â”‚
â”‚  2. Compute graph Laplacian                                                â”‚
â”‚  3. Find eigenvectors of Laplacian                                         â”‚
â”‚  4. Cluster in spectral space with K-means                                 â”‚
â”‚                                                                             â”‚
â”‚  Benefits: Captures non-convex cluster shapes                              â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                             â”‚
â”‚  ALGORITHM 4: Topic Modeling (LDA/NMF) (Interpretable)                      â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                       â”‚
â”‚                                                                             â”‚
â”‚  Treat domains as "topics" in a topic model                                â”‚
â”‚                                                                             â”‚
â”‚  Benefits:                                                                  â”‚
â”‚  â€¢ Each domain has interpretable keywords                                  â”‚
â”‚  â€¢ Soft clustering: files can belong to multiple domains                   â”‚
â”‚  â€¢ Can generate domain names from top keywords                             â”‚
â”‚                                                                             â”‚
â”‚  LDA Output Example:                                                       â”‚
â”‚  Domain 0 (0.23): payment, invoice, billing, refund, charge               â”‚
â”‚  Domain 1 (0.19): user, auth, login, permission, role                     â”‚
â”‚  Domain 2 (0.15): order, cart, checkout, shipping, delivery               â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.4 Domain Naming Algorithm

```python
def auto_name_domain(cluster_files: list, extracted_tokens: dict) -> str:
    """
    Automatically generate a domain name from clustered files.
    
    Algorithm:
    1. Aggregate all tokens from cluster files
    2. Apply TF-IDF within the cluster (corpus = all clusters)
    3. Select top N distinctive terms
    4. Apply naming heuristics:
       - Prefer nouns over verbs
       - Prefer singular over plural
       - Remove generic terms
       - Combine related terms
    5. Format as domain name
    """
    
    # Collect tokens from cluster
    cluster_tokens = Counter()
    for file in cluster_files:
        cluster_tokens.update(extracted_tokens[file])
    
    # Calculate distinctiveness (TF-IDF across clusters)
    distinctive_terms = calculate_tfidf_distinctiveness(
        cluster_tokens, 
        all_clusters_tokens
    )
    
    # Filter and rank terms
    ranked_terms = []
    for term, score in distinctive_terms:
        if is_noun(term) and not is_generic(term):
            ranked_terms.append((term, score * 1.5))  # Boost nouns
        elif is_verb(term) and is_domain_verb(term):
            ranked_terms.append((term, score))
    
    # Generate name from top terms
    top_terms = sorted(ranked_terms, key=lambda x: -x[1])[:3]
    
    # Apply naming patterns
    if len(top_terms) == 1:
        return capitalize(top_terms[0][0])
    elif are_related(top_terms[0][0], top_terms[1][0]):
        return capitalize(top_terms[0][0])  # Use primary
    else:
        return f"{capitalize(top_terms[0][0])}-{capitalize(top_terms[1][0])}"
```

### 4.5 Multi-Domain Entity Detection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MULTI-DOMAIN ENTITY DETECTION                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Some entities legitimately span multiple domains:                          â”‚
â”‚  â€¢ OrderPaymentService â†’ Order + Payment                                    â”‚
â”‚  â€¢ UserAuthorizationHandler â†’ User + Auth                                   â”‚
â”‚  â€¢ BillingReportGenerator â†’ Billing + Reporting                            â”‚
â”‚                                                                             â”‚
â”‚  DETECTION ALGORITHM:                                                       â”‚
â”‚                                                                             â”‚
â”‚  1. Compute soft cluster membership using HDBSCAN probability              â”‚
â”‚     membership = hdbscan.membership_vector(entity_embedding)               â”‚
â”‚                                                                             â”‚
â”‚  2. Identify multi-domain candidates:                                       â”‚
â”‚     if count(membership > 0.2) >= 2:                                       â”‚
â”‚         entity.is_multi_domain = True                                      â”‚
â”‚         entity.domain_affinities = {                                       â”‚
â”‚             domain_id: membership[domain_id]                               â”‚
â”‚             for domain_id, prob in enumerate(membership)                   â”‚
â”‚             if prob > 0.2                                                  â”‚
â”‚         }                                                                  â”‚
â”‚                                                                             â”‚
â”‚  3. Classify multi-domain entity type:                                     â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚     â”‚ Type               â”‚ Detection Pattern                          â”‚   â”‚
â”‚     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚
â”‚     â”‚ Integration Point  â”‚ High affinity to 2 domains, mediator role â”‚   â”‚
â”‚     â”‚ God Class          â”‚ High affinity to 3+ domains                â”‚   â”‚
â”‚     â”‚ Shared Utility     â”‚ Low-medium affinity to many domains       â”‚   â”‚
â”‚     â”‚ Legitimate Bridge  â”‚ High affinity to 2 related domains        â”‚   â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  4. Generate recommendations:                                              â”‚
â”‚     - God Class â†’ "Consider splitting into domain-specific services"       â”‚
â”‚     - Integration Point â†’ "Document as intentional integration"            â”‚
â”‚     - Shared Utility â†’ "Move to shared/common module"                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Technology Choices

### 5.1 Core Technology Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       TECHNOLOGY STACK                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  COMPONENT              TECHNOLOGY                  RATIONALE               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                                             â”‚
â”‚  AST Parsing           Tree-sitter (multi-lang)   Fast, incremental,       â”‚
â”‚                        + Roslyn (.NET)             language-specific depth  â”‚
â”‚                        + TypeScript Compiler       for complex languages    â”‚
â”‚                                                                             â”‚
â”‚  NLP Processing        spaCy (lemmatization)      Industrial NLP library   â”‚
â”‚                        NLTK (tokenization)         Comprehensive toolkit    â”‚
â”‚                                                                             â”‚
â”‚  Word Embeddings       Gensim (Word2Vec/FastText)  Proven, efficient       â”‚
â”‚                        + sentence-transformers      Pre-trained models      â”‚
â”‚                                                                             â”‚
â”‚  Code Embeddings       CodeBERT (optional GPU)     State-of-art code       â”‚
â”‚                        UniXcoder (multilingual)    understanding           â”‚
â”‚                                                                             â”‚
â”‚  Vector Storage        Qdrant                      Purpose-built vector DB  â”‚
â”‚                        (alt: Chroma for embedded)   Fast similarity search  â”‚
â”‚                                                                             â”‚
â”‚  Clustering            scikit-learn (baseline)     Comprehensive library   â”‚
â”‚                        HDBSCAN (density-based)     No K required           â”‚
â”‚                        umap-learn (dim reduction)   Preserves structure    â”‚
â”‚                                                                             â”‚
â”‚  Graph Analysis        NetworkX (Python)           Standard graph lib      â”‚
â”‚                        igraph (performance)         For large graphs        â”‚
â”‚                                                                             â”‚
â”‚  Visualization         D3.js (frontend)            Interactive clusters    â”‚
â”‚                        Plotly (backend reports)    Static exports          â”‚
â”‚                        UMAP plots                   2D projections          â”‚
â”‚                                                                             â”‚
â”‚  API Framework         FastAPI                     Existing LFCA stack     â”‚
â”‚                        Pydantic (validation)        Type safety            â”‚
â”‚                                                                             â”‚
â”‚  Caching               Redis                       Embedding cache         â”‚
â”‚                        SQLite (local)              File metadata           â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Python Dependencies

```toml
# pyproject.toml additions

[project.optional-dependencies]
semantic = [
    # AST Parsing
    "tree-sitter>=0.20.0",
    "tree-sitter-python>=0.20.0",
    "tree-sitter-javascript>=0.20.0",
    "tree-sitter-typescript>=0.20.0",
    "tree-sitter-c-sharp>=0.20.0",
    "tree-sitter-java>=0.20.0",
    
    # NLP
    "spacy>=3.5.0",
    "nltk>=3.8.0",
    
    # Embeddings
    "gensim>=4.3.0",
    "sentence-transformers>=2.2.0",
    
    # Vector Storage
    "qdrant-client>=1.7.0",
    # Alternative: "chromadb>=0.4.0",
    
    # Clustering & ML
    "hdbscan>=0.8.33",
    "umap-learn>=0.5.3",
    "scikit-learn>=1.3.0",
    
    # Graph
    "networkx>=3.0",
    "python-igraph>=0.10.0",
    
    # Visualization
    "plotly>=5.18.0",
    "matplotlib>=3.8.0",
]

semantic-gpu = [
    "torch>=2.0.0",
    "transformers>=4.35.0",  # For CodeBERT
]
```

### 5.3 Technology Profiles

Pre-configured profiles for common technology stacks:

```yaml
# configs/tech_profiles/dotnet.yaml
name: ".NET / C#"
version: "1.0"

languages:
  - csharp
  - fsharp

parsers:
  csharp:
    primary: roslyn  # Best accuracy for C#
    fallback: tree-sitter-c-sharp

token_filters:
  # Framework tokens to exclude
  aspnetcore:
    - Controller
    - ApiController
    - ControllerBase
    - ActionResult
    - IActionResult
    - Task<*>
    - HttpGet
    - HttpPost
    - HttpPut
    - HttpDelete
    - Authorize
    - AllowAnonymous
    - FromBody
    - FromQuery
    - FromRoute
    
  entity_framework:
    - DbContext
    - DbSet
    - IQueryable
    - EntityTypeConfiguration
    - OnModelCreating
    - HasKey
    - HasIndex
    - ToTable
    - Migration
    
  dependency_injection:
    - IServiceCollection
    - IServiceProvider
    - ServiceLifetime
    - AddScoped
    - AddSingleton
    - AddTransient
    - IOptions
    - IConfiguration
    
  mediatr:
    - IRequest
    - IRequestHandler
    - INotification
    - INotificationHandler
    - MediatR
    
  common_patterns:
    - Repository
    - IRepository
    - UnitOfWork
    - IUnitOfWork
    - Specification
    - Handler
    - Command
    - Query
    - Dto
    - ViewModel
    - Request
    - Response

  generic_base_types:
    - object
    - string
    - int
    - long
    - bool
    - decimal
    - DateTime
    - Guid
    - Task
    - Async
    - CancellationToken

# Namespace patterns to classify as infrastructure (not domain)
infrastructure_patterns:
  - "*.Infrastructure.*"
  - "*.Persistence.*"
  - "*.Data.*"
  - "*.Migrations.*"
  - "*.Configuration.*"

# Test file patterns to handle separately
test_patterns:
  - "*Tests.cs"
  - "*Test.cs"
  - "*.Specs.cs"
  - "*Fixture.cs"
```

---

## 6. Architecture

### 6.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEMANTIC CLUSTERING ARCHITECTURE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                           API LAYER                                   â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚  /domains â”‚  â”‚/similarityâ”‚  â”‚ /classify â”‚  â”‚ /visualizations  â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚              â”‚              â”‚                  â”‚               â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                   â”‚                                         â”‚
â”‚                                   â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        SERVICE LAYER                                  â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚  â”‚
â”‚  â”‚  â”‚  SemanticAnalyzer   â”‚     â”‚  DomainClusterer    â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚                     â”‚     â”‚                     â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ parse_codebase() â”‚     â”‚  â€¢ discover()       â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ extract_tokens() â”‚     â”‚  â€¢ classify()       â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ filter_tokens()  â”‚     â”‚  â€¢ find_similar()   â”‚                 â”‚  â”‚
â”‚  â”‚  â”‚  â€¢ compute_embeds() â”‚     â”‚  â€¢ get_boundaries() â”‚                 â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â”‚
â”‚  â”‚             â”‚                           â”‚                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                â”‚                           â”‚                                 â”‚
â”‚                â–¼                           â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                        PROCESSING LAYER                               â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”‚
â”‚  â”‚  â”‚  AST Parsers  â”‚  â”‚  Embedders    â”‚  â”‚  Clusterers   â”‚             â”‚  â”‚
â”‚  â”‚  â”‚               â”‚  â”‚               â”‚  â”‚               â”‚             â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ TreeSitter  â”‚  â”‚ â€¢ TF-IDF      â”‚  â”‚ â€¢ HDBSCAN     â”‚             â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ Roslyn      â”‚  â”‚ â€¢ Word2Vec    â”‚  â”‚ â€¢ Hierarchicalâ”‚             â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ TypeScript  â”‚  â”‚ â€¢ CodeBERT    â”‚  â”‚ â€¢ Spectral    â”‚             â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ JavaParser  â”‚  â”‚ â€¢ Graph       â”‚  â”‚ â€¢ LDA/NMF     â”‚             â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚
â”‚  â”‚          â”‚                  â”‚                  â”‚                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚                  â”‚                  â”‚                         â”‚
â”‚             â–¼                  â–¼                  â–¼                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                         STORAGE LAYER                                 â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚  â”‚
â”‚  â”‚  â”‚ Token Store   â”‚  â”‚ Vector Store  â”‚  â”‚ Cluster Store â”‚             â”‚  â”‚
â”‚  â”‚  â”‚   (SQLite)    â”‚  â”‚   (Qdrant)    â”‚  â”‚   (SQLite)    â”‚             â”‚  â”‚
â”‚  â”‚  â”‚               â”‚  â”‚               â”‚  â”‚               â”‚             â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ file_tokens â”‚  â”‚ â€¢ embeddings  â”‚  â”‚ â€¢ domains     â”‚             â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ tech_filter â”‚  â”‚ â€¢ similarity  â”‚  â”‚ â€¢ membership  â”‚             â”‚  â”‚
â”‚  â”‚  â”‚ â€¢ metadata    â”‚  â”‚ â€¢ index       â”‚  â”‚ â€¢ hierarchy   â”‚             â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚  â”‚
â”‚  â”‚                                                                       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Module Structure

```
lfca/
â”œâ”€â”€ semantic/                          # New semantic module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ parsing/                       # AST parsing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                    # BaseParser interface
â”‚   â”‚   â”œâ”€â”€ tree_sitter_parser.py      # Generic Tree-sitter
â”‚   â”‚   â”œâ”€â”€ csharp_parser.py           # C# with Roslyn
â”‚   â”‚   â”œâ”€â”€ python_parser.py           # Python ast module
â”‚   â”‚   â”œâ”€â”€ typescript_parser.py       # TypeScript compiler
â”‚   â”‚   â””â”€â”€ registry.py                # Parser registry
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/                    # Token extraction
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ extractor.py               # Token extractor
â”‚   â”‚   â”œâ”€â”€ splitters.py               # CamelCase, snake_case
â”‚   â”‚   â””â”€â”€ enrichment.py              # Lemmatization, synonyms
â”‚   â”‚
â”‚   â”œâ”€â”€ filtering/                     # Technical token filtering
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ filters.py                 # Token filter logic
â”‚   â”‚   â”œâ”€â”€ profiles/                  # Tech profile configs
â”‚   â”‚   â”‚   â”œâ”€â”€ dotnet.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ react.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ spring.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ django.yaml
â”‚   â”‚   â”‚   â””â”€â”€ generic.yaml
â”‚   â”‚   â””â”€â”€ custom.py                  # Custom filter support
â”‚   â”‚
â”‚   â”œâ”€â”€ embedding/                     # Embedding generation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                    # BaseEmbedder interface
â”‚   â”‚   â”œâ”€â”€ tfidf_embedder.py          # TF-IDF + LSA
â”‚   â”‚   â”œâ”€â”€ word2vec_embedder.py       # Word2Vec aggregation
â”‚   â”‚   â”œâ”€â”€ codebert_embedder.py       # CodeBERT (optional)
â”‚   â”‚   â”œâ”€â”€ graph_embedder.py          # Graph neural network
â”‚   â”‚   â”œâ”€â”€ hybrid_embedder.py         # Ensemble of above
â”‚   â”‚   â””â”€â”€ registry.py                # Embedder registry
â”‚   â”‚
â”‚   â”œâ”€â”€ clustering/                    # Domain clustering
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py                    # BaseClusterer interface
â”‚   â”‚   â”œâ”€â”€ hdbscan_clusterer.py       # HDBSCAN implementation
â”‚   â”‚   â”œâ”€â”€ hierarchical_clusterer.py  # Agglomerative
â”‚   â”‚   â”œâ”€â”€ spectral_clusterer.py      # Spectral clustering
â”‚   â”‚   â”œâ”€â”€ topic_clusterer.py         # LDA/NMF topic modeling
â”‚   â”‚   â””â”€â”€ registry.py                # Clusterer registry
â”‚   â”‚
â”‚   â”œâ”€â”€ domains/                       # Domain management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ discovery.py               # Domain discovery service
â”‚   â”‚   â”œâ”€â”€ classification.py          # Entity classification
â”‚   â”‚   â”œâ”€â”€ naming.py                  # Auto-naming domains
â”‚   â”‚   â”œâ”€â”€ boundaries.py              # Boundary detection
â”‚   â”‚   â””â”€â”€ multi_domain.py            # Multi-domain entities
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                       # Persistence
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ token_store.py             # SQLite token storage
â”‚   â”‚   â”œâ”€â”€ vector_store.py            # Qdrant integration
â”‚   â”‚   â””â”€â”€ domain_store.py            # Domain results storage
â”‚   â”‚
â”‚   â”œâ”€â”€ similarity/                    # Similarity search
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ search.py                  # Similarity search service
â”‚   â”‚   â””â”€â”€ ranking.py                 # Result ranking
â”‚   â”‚
â”‚   â””â”€â”€ config.py                      # Semantic config
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ semantic.py                # Semantic API endpoints
â”‚
â””â”€â”€ frontend/
    â””â”€â”€ src/components/
        â””â”€â”€ semantic/                  # Semantic UI components
            â”œâ”€â”€ DomainGraph.tsx
            â”œâ”€â”€ DomainList.tsx
            â”œâ”€â”€ SimilarityPanel.tsx
            â””â”€â”€ ClusterViz.tsx
```

### 6.3 Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          DATA FLOW DIAGRAM                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PHASE 1: EXTRACTION (Run Once, Update Incrementally)                â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Source Files â”€â”€â–¶ Parse â”€â”€â–¶ Extract â”€â”€â–¶ Filter â”€â”€â–¶ Token Store      â”‚   â”‚
â”‚  â”‚                    AST      Tokens     Tech                (SQLite)  â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Example:                                                           â”‚   â”‚
â”‚  â”‚  PaymentService.cs                                                  â”‚   â”‚
â”‚  â”‚    â†’ AST nodes: [class:PaymentService, method:ProcessPayment, ...]  â”‚   â”‚
â”‚  â”‚    â†’ Tokens: [payment, service, process, refund, invoice, ...]      â”‚   â”‚
â”‚  â”‚    â†’ Filtered: [payment, process, refund, invoice] (removed generic) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                     â”‚
â”‚                                       â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PHASE 2: EMBEDDING (Computed Per Embedder Config)                   â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Token Store â”€â”€â–¶ Vectorize â”€â”€â–¶ Reduce Dims â”€â”€â–¶ Vector Store         â”‚   â”‚
â”‚  â”‚                  (TF-IDF,     (UMAP/PCA)       (Qdrant)              â”‚   â”‚
â”‚  â”‚                   Word2Vec)                                         â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Example:                                                           â”‚   â”‚
â”‚  â”‚  PaymentService.cs                                                  â”‚   â”‚
â”‚  â”‚    â†’ TF-IDF: [0.2, 0.8, 0.1, ...] (100d)                           â”‚   â”‚
â”‚  â”‚    â†’ Word2Vec avg: [0.3, -0.1, 0.5, ...] (100d)                    â”‚   â”‚
â”‚  â”‚    â†’ Combined: [0.25, 0.35, ...] (256d)                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                     â”‚
â”‚                                       â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PHASE 3: CLUSTERING (Triggered by User or Schedule)                 â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Vector Store â”€â”€â–¶ Cluster â”€â”€â–¶ Name â”€â”€â–¶ Analyze â”€â”€â–¶ Domain Store     â”‚   â”‚
â”‚  â”‚                  (HDBSCAN)    Domains   Boundaries   (SQLite)        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Example:                                                           â”‚   â”‚
â”‚  â”‚  Cluster 0: [PaymentService, RefundHandler, InvoiceGenerator, ...]  â”‚   â”‚
â”‚  â”‚    â†’ Name: "Payment"                                                â”‚   â”‚
â”‚  â”‚    â†’ Keywords: [payment, refund, invoice, charge, billing]          â”‚   â”‚
â”‚  â”‚    â†’ Cohesion: 0.87                                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                       â”‚                                     â”‚
â”‚                                       â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ PHASE 4: QUERY (Real-time)                                          â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Query â”€â”€â–¶ Embed â”€â”€â–¶ Search â”€â”€â–¶ Rank â”€â”€â–¶ Response                   â”‚   â”‚
â”‚  â”‚                      (Qdrant)                                        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚  Examples:                                                          â”‚   â”‚
â”‚  â”‚  â€¢ "Find similar to PaymentService" â†’ [RefundHandler, BillingAPI]   â”‚   â”‚
â”‚  â”‚  â€¢ "Classify OrderProcessor" â†’ Primary: Order (0.8), Secondary: ... â”‚   â”‚
â”‚  â”‚  â€¢ "Show Payment domain" â†’ [12 files, 3 subdomains, 5 bridges]     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. API Design

### 7.1 REST API Endpoints

```yaml
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    SEMANTIC CLUSTERING API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# DOMAIN DISCOVERY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

POST /repos/{repo_id}/semantic/analyze:
  summary: Start semantic analysis of repository
  requestBody:
    content:
      application/json:
        schema:
          type: object
          properties:
            config:
              $ref: '#/components/schemas/SemanticConfig'
            directories:
              type: array
              items: { type: string }
              description: "Directories to analyze (empty = all)"
            exclude_patterns:
              type: array
              items: { type: string }
              description: "Glob patterns to exclude"
            tech_profile:
              type: string
              enum: [dotnet, react, spring, django, generic, custom]
            custom_filters:
              type: array
              items: { type: string }
              description: "Additional tokens to filter"
  responses:
    202:
      description: Analysis job started
      content:
        application/json:
          schema:
            type: object
            properties:
              job_id: { type: string }
              status: { type: string, enum: [queued, running] }

GET /repos/{repo_id}/semantic/domains:
  summary: Get discovered domains
  parameters:
    - name: run_id
      in: query
      description: "Specific run ID (latest if omitted)"
      schema: { type: string }
    - name: min_size
      in: query
      description: "Minimum domain size"
      schema: { type: integer, default: 3 }
    - name: include_outliers
      in: query
      description: "Include unclustered files"
      schema: { type: boolean, default: false }
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/DomainDiscoveryResult'

GET /repos/{repo_id}/semantic/domains/{domain_id}:
  summary: Get domain details
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/DomainDetails'

GET /repos/{repo_id}/semantic/domains/{domain_id}/files:
  summary: Get files in domain
  parameters:
    - name: sort_by
      in: query
      schema: { type: string, enum: [affinity, name, path] }
    - name: limit
      in: query
      schema: { type: integer, default: 100 }
  responses:
    200:
      content:
        application/json:
          schema:
            type: array
            items:
              $ref: '#/components/schemas/DomainFile'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLASSIFICATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

POST /repos/{repo_id}/semantic/classify:
  summary: Classify entity into domains
  requestBody:
    content:
      application/json:
        schema:
          type: object
          properties:
            path:
              type: string
              description: "File path to classify"
            content:
              type: string
              description: "Optional: raw content (for uncommitted files)"
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ClassificationResult'

POST /repos/{repo_id}/semantic/classify/batch:
  summary: Classify multiple entities
  requestBody:
    content:
      application/json:
        schema:
          type: object
          properties:
            paths:
              type: array
              items: { type: string }
  responses:
    200:
      content:
        application/json:
          schema:
            type: array
            items:
              $ref: '#/components/schemas/ClassificationResult'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# SIMILARITY SEARCH
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GET /repos/{repo_id}/semantic/similar:
  summary: Find similar files
  parameters:
    - name: path
      in: query
      required: true
      schema: { type: string }
    - name: limit
      in: query
      schema: { type: integer, default: 20 }
    - name: min_similarity
      in: query
      schema: { type: number, default: 0.5 }
    - name: same_domain
      in: query
      description: "Only return files from same domain"
      schema: { type: boolean, default: false }
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/SimilarityResult'

POST /repos/{repo_id}/semantic/similar/query:
  summary: Find similar files by description
  description: "Natural language query for similar code"
  requestBody:
    content:
      application/json:
        schema:
          type: object
          properties:
            query:
              type: string
              description: "Natural language description"
              example: "code that handles credit card payments"
            limit:
              type: integer
              default: 20
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/SimilarityResult'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# BOUNDARIES & ANALYSIS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GET /repos/{repo_id}/semantic/boundaries:
  summary: Get domain boundary analysis
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/BoundaryAnalysis'

GET /repos/{repo_id}/semantic/bridges:
  summary: Get files spanning multiple domains
  parameters:
    - name: min_domains
      in: query
      schema: { type: integer, default: 2 }
  responses:
    200:
      content:
        application/json:
          schema:
            type: array
            items:
              $ref: '#/components/schemas/BridgeEntity'

GET /repos/{repo_id}/semantic/coupling:
  summary: Get inter-domain coupling matrix
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/DomainCouplingMatrix'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# VISUALIZATION DATA
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GET /repos/{repo_id}/semantic/visualization/graph:
  summary: Get domain graph for visualization
  parameters:
    - name: level
      in: query
      description: "Aggregation level"
      schema: { type: string, enum: [domains, subdomains, files] }
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/DomainGraph'

GET /repos/{repo_id}/semantic/visualization/projection:
  summary: Get 2D projection of embeddings
  parameters:
    - name: method
      in: query
      schema: { type: string, enum: [umap, tsne, pca], default: umap }
    - name: color_by
      in: query
      schema: { type: string, enum: [domain, directory, extension] }
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/ProjectionData'

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIGURATION
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

GET /semantic/profiles:
  summary: List available technology profiles
  responses:
    200:
      content:
        application/json:
          schema:
            type: array
            items:
              $ref: '#/components/schemas/TechProfile'

GET /semantic/profiles/{profile_id}:
  summary: Get technology profile details
  responses:
    200:
      content:
        application/json:
          schema:
            $ref: '#/components/schemas/TechProfileDetails'

POST /semantic/profiles:
  summary: Create custom technology profile
  requestBody:
    content:
      application/json:
        schema:
          $ref: '#/components/schemas/TechProfileCreate'
```

### 7.2 Response Schemas

```yaml
components:
  schemas:
    
    SemanticConfig:
      type: object
      properties:
        embedding:
          type: object
          properties:
            method:
              type: string
              enum: [tfidf, word2vec, codebert, hybrid]
              default: hybrid
            dimensions:
              type: integer
              default: 256
        clustering:
          type: object
          properties:
            algorithm:
              type: string
              enum: [hdbscan, hierarchical, spectral, lda]
              default: hdbscan
            min_cluster_size:
              type: integer
              default: 5
            min_samples:
              type: integer
              default: 3
        filters:
          type: object
          properties:
            tech_profile:
              type: string
              default: auto
            custom_stopwords:
              type: array
              items: { type: string }
            min_token_frequency:
              type: integer
              default: 2

    DomainDiscoveryResult:
      type: object
      properties:
        run_id:
          type: string
        created_at:
          type: string
          format: date-time
        config:
          $ref: '#/components/schemas/SemanticConfig'
        stats:
          type: object
          properties:
            files_analyzed: { type: integer }
            tokens_extracted: { type: integer }
            domains_found: { type: integer }
            outlier_files: { type: integer }
        domains:
          type: array
          items:
            $ref: '#/components/schemas/DomainSummary'
        
    DomainSummary:
      type: object
      properties:
        domain_id:
          type: string
        name:
          type: string
          description: "Auto-generated or user-defined name"
        keywords:
          type: array
          items: { type: string }
          description: "Top keywords characterizing domain"
        file_count:
          type: integer
        cohesion_score:
          type: number
          description: "Internal cohesion (0-1)"
        isolation_score:
          type: number
          description: "Separation from other domains (0-1)"
        subdomains:
          type: array
          items:
            $ref: '#/components/schemas/DomainSummary'

    DomainDetails:
      type: object
      properties:
        domain_id:
          type: string
        name:
          type: string
        keywords:
          type: array
          items:
            type: object
            properties:
              term: { type: string }
              weight: { type: number }
        files:
          type: array
          items:
            $ref: '#/components/schemas/DomainFile'
        metrics:
          type: object
          properties:
            cohesion: { type: number }
            isolation: { type: number }
            avg_file_affinity: { type: number }
            bridge_file_count: { type: integer }
        coupled_domains:
          type: array
          items:
            type: object
            properties:
              domain_id: { type: string }
              domain_name: { type: string }
              coupling_strength: { type: number }
              coupling_files: { type: integer }

    DomainFile:
      type: object
      properties:
        file_id:
          type: integer
        path:
          type: string
        affinity:
          type: number
          description: "How strongly file belongs to domain (0-1)"
        is_bridge:
          type: boolean
          description: "True if file spans multiple domains"
        other_domains:
          type: array
          items:
            type: object
            properties:
              domain_id: { type: string }
              affinity: { type: number }

    ClassificationResult:
      type: object
      properties:
        path:
          type: string
        primary_domain:
          type: object
          properties:
            domain_id: { type: string }
            name: { type: string }
            affinity: { type: number }
        secondary_domains:
          type: array
          items:
            type: object
            properties:
              domain_id: { type: string }
              name: { type: string }
              affinity: { type: number }
        confidence:
          type: number
          description: "Classification confidence (0-1)"
        is_outlier:
          type: boolean
          description: "True if doesn't fit any domain well"
        reasoning:
          type: array
          items:
            type: string
          description: "Explanation of classification"

    SimilarityResult:
      type: object
      properties:
        query_path:
          type: string
        similar_files:
          type: array
          items:
            type: object
            properties:
              path: { type: string }
              similarity: { type: number }
              shared_concepts:
                type: array
                items: { type: string }
              relationship:
                type: string
                enum: [same_domain, related_domain, utility, test]
              domain:
                type: object
                properties:
                  domain_id: { type: string }
                  name: { type: string }

    BridgeEntity:
      type: object
      properties:
        path:
          type: string
        file_id:
          type: integer
        domains:
          type: array
          items:
            type: object
            properties:
              domain_id: { type: string }
              name: { type: string }
              affinity: { type: number }
        classification:
          type: string
          enum: [integration_point, god_class, shared_utility, legitimate_bridge]
        recommendation:
          type: string

    DomainCouplingMatrix:
      type: object
      properties:
        domains:
          type: array
          items:
            type: object
            properties:
              domain_id: { type: string }
              name: { type: string }
        coupling_matrix:
          type: array
          items:
            type: array
            items: { type: number }
          description: "NxN matrix of coupling scores"
        strong_couplings:
          type: array
          items:
            type: object
            properties:
              from_domain: { type: string }
              to_domain: { type: string }
              strength: { type: number }
              coupling_files:
                type: array
                items: { type: string }

    DomainGraph:
      type: object
      properties:
        nodes:
          type: array
          items:
            type: object
            properties:
              id: { type: string }
              name: { type: string }
              type: { type: string, enum: [domain, subdomain, file] }
              size: { type: integer }
              color: { type: string }
              metrics:
                type: object
        edges:
          type: array
          items:
            type: object
            properties:
              source: { type: string }
              target: { type: string }
              weight: { type: number }
              type: { type: string }

    ProjectionData:
      type: object
      properties:
        method:
          type: string
        points:
          type: array
          items:
            type: object
            properties:
              file_id: { type: integer }
              path: { type: string }
              x: { type: number }
              y: { type: number }
              domain_id: { type: string }
              domain_name: { type: string }
              color: { type: string }
```

---

## 8. Data Models

### 8.1 Database Schema

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
--                    SEMANTIC CLUSTERING SCHEMA
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

-- data/repos/<repo_id>/artifacts/indexes/semantic.sqlite

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- SEMANTIC ANALYSIS RUNS
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE semantic_runs (
    run_id TEXT PRIMARY KEY,
    repo_id TEXT NOT NULL,
    state TEXT NOT NULL,  -- queued|running|complete|failed
    created_at TEXT NOT NULL,
    finished_at TEXT,
    
    -- Configuration
    config_json TEXT NOT NULL,
    tech_profile TEXT,
    directories_json TEXT,  -- Analyzed directories
    
    -- Git reference
    git_head_oid TEXT,
    
    -- Statistics
    files_analyzed INTEGER DEFAULT 0,
    tokens_extracted INTEGER DEFAULT 0,
    domains_found INTEGER DEFAULT 0,
    
    error TEXT
);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- EXTRACTED TOKENS
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE file_tokens (
    file_id INTEGER NOT NULL,
    run_id TEXT NOT NULL,
    
    -- Raw extraction
    tokens_json TEXT NOT NULL,  -- Array of tokens with positions
    token_count INTEGER,
    
    -- Filtered tokens (after tech filter)
    filtered_tokens_json TEXT,
    filtered_count INTEGER,
    
    -- Metadata
    language TEXT,
    lines_of_code INTEGER,
    class_count INTEGER,
    method_count INTEGER,
    
    PRIMARY KEY (file_id, run_id),
    FOREIGN KEY (run_id) REFERENCES semantic_runs(run_id)
);

CREATE INDEX idx_file_tokens_run ON file_tokens(run_id);

-- Token frequency for TF-IDF computation
CREATE TABLE token_frequencies (
    run_id TEXT NOT NULL,
    token TEXT NOT NULL,
    document_frequency INTEGER,  -- How many files contain token
    total_frequency INTEGER,     -- Total occurrences
    
    PRIMARY KEY (run_id, token),
    FOREIGN KEY (run_id) REFERENCES semantic_runs(run_id)
);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- DOMAINS
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE domains (
    domain_id TEXT PRIMARY KEY,
    run_id TEXT NOT NULL,
    parent_domain_id TEXT,  -- For hierarchical domains
    
    -- Identity
    name TEXT NOT NULL,
    auto_named BOOLEAN DEFAULT TRUE,
    
    -- Characterization
    keywords_json TEXT,  -- Top keywords with weights
    
    -- Metrics
    file_count INTEGER,
    cohesion_score REAL,
    isolation_score REAL,
    
    -- Hierarchy level (0 = top-level)
    level INTEGER DEFAULT 0,
    
    FOREIGN KEY (run_id) REFERENCES semantic_runs(run_id),
    FOREIGN KEY (parent_domain_id) REFERENCES domains(domain_id)
);

CREATE INDEX idx_domains_run ON domains(run_id);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- FILE-DOMAIN MEMBERSHIP
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE domain_membership (
    file_id INTEGER NOT NULL,
    domain_id TEXT NOT NULL,
    run_id TEXT NOT NULL,
    
    -- Membership strength
    affinity REAL NOT NULL,  -- 0-1, how strongly file belongs
    is_primary BOOLEAN DEFAULT FALSE,
    
    -- Classification
    is_bridge BOOLEAN DEFAULT FALSE,  -- Spans multiple domains
    
    PRIMARY KEY (file_id, domain_id, run_id),
    FOREIGN KEY (domain_id) REFERENCES domains(domain_id)
);

CREATE INDEX idx_membership_file ON domain_membership(file_id, run_id);
CREATE INDEX idx_membership_domain ON domain_membership(domain_id);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- INTER-DOMAIN COUPLING
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE domain_coupling (
    run_id TEXT NOT NULL,
    domain_a_id TEXT NOT NULL,
    domain_b_id TEXT NOT NULL,
    
    -- Coupling metrics
    coupling_strength REAL,  -- Computed from shared files & proximity
    bridge_file_count INTEGER,
    shared_keywords_json TEXT,
    
    PRIMARY KEY (run_id, domain_a_id, domain_b_id),
    FOREIGN KEY (domain_a_id) REFERENCES domains(domain_id),
    FOREIGN KEY (domain_b_id) REFERENCES domains(domain_id)
);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- BRIDGE ENTITIES (Multi-Domain Files)
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE bridge_entities (
    file_id INTEGER NOT NULL,
    run_id TEXT NOT NULL,
    
    -- Classification
    entity_type TEXT,  -- integration_point, god_class, shared_utility, legitimate_bridge
    domain_count INTEGER,
    
    -- Recommendations
    recommendation TEXT,
    
    PRIMARY KEY (file_id, run_id)
);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- TECHNOLOGY FILTERS (Custom Profiles)
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE custom_profiles (
    profile_id TEXT PRIMARY KEY,
    repo_id TEXT,  -- NULL for global profiles
    name TEXT NOT NULL,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    
    -- Profile definition
    base_profile TEXT,  -- Extend existing profile
    config_json TEXT NOT NULL
);
```

### 8.2 Vector Store Schema (Qdrant)

```python
# qdrant_schema.py

from qdrant_client.models import VectorParams, Distance

SEMANTIC_COLLECTION = "semantic_embeddings"

VECTOR_PARAMS = VectorParams(
    size=256,  # Hybrid embedding dimension
    distance=Distance.COSINE
)

# Payload schema
PAYLOAD_SCHEMA = {
    "file_id": "integer",
    "run_id": "keyword",
    "repo_id": "keyword",
    "path": "text",
    "language": "keyword",
    "domain_id": "keyword",
    "domain_name": "keyword",
    "is_bridge": "bool",
    
    # For filtering
    "directory": "keyword",  # Top-level directory
    "extension": "keyword",
    
    # Metadata for display
    "class_names": "keyword[]",
    "top_tokens": "keyword[]"
}
```

---

## 9. Implementation Roadmap

### 9.1 Phase Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      IMPLEMENTATION PHASES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  PHASE 1: Foundation (Weeks 1-3)                                            â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                            â”‚
â”‚  â–¡ AST parsing infrastructure (Tree-sitter multi-lang)                      â”‚
â”‚  â–¡ Token extraction pipeline                                                â”‚
â”‚  â–¡ Basic TF-IDF embeddings                                                  â”‚
â”‚  â–¡ Technology filter framework + .NET profile                               â”‚
â”‚  â–¡ Storage layer (SQLite schema)                                            â”‚
â”‚                                                                             â”‚
â”‚  PHASE 2: Clustering Core (Weeks 4-6)                                       â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                        â”‚
â”‚  â–¡ HDBSCAN clustering implementation                                        â”‚
â”‚  â–¡ Domain auto-naming algorithm                                             â”‚
â”‚  â–¡ Multi-domain entity detection                                            â”‚
â”‚  â–¡ API endpoints (basic)                                                    â”‚
â”‚  â–¡ CLI commands                                                             â”‚
â”‚                                                                             â”‚
â”‚  PHASE 3: Enhanced Embeddings (Weeks 7-9)                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                   â”‚
â”‚  â–¡ Word2Vec training on codebase                                            â”‚
â”‚  â–¡ Hybrid embedding pipeline                                                â”‚
â”‚  â–¡ Qdrant vector storage integration                                        â”‚
â”‚  â–¡ Similarity search API                                                    â”‚
â”‚  â–¡ Additional tech profiles (React, Spring)                                 â”‚
â”‚                                                                             â”‚
â”‚  PHASE 4: Visualization & UI (Weeks 10-12)                                  â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                  â”‚
â”‚  â–¡ Domain graph visualization (D3.js)                                       â”‚
â”‚  â–¡ 2D projection view (UMAP)                                               â”‚
â”‚  â–¡ Domain explorer panel                                                    â”‚
â”‚  â–¡ Similarity panel                                                         â”‚
â”‚  â–¡ Integration with existing LFCA views                                     â”‚
â”‚                                                                             â”‚
â”‚  PHASE 5: Advanced Features (Weeks 13-16)                                   â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                                   â”‚
â”‚  â–¡ CodeBERT embeddings (optional GPU)                                       â”‚
â”‚  â–¡ Natural language queries                                                 â”‚
â”‚  â–¡ Hierarchical domain discovery                                            â”‚
â”‚  â–¡ Domain drift detection                                                   â”‚
â”‚  â–¡ CI integration (domain boundary checks)                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 Detailed Phase 1 Tasks

```
PHASE 1: Foundation (Weeks 1-3)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Week 1: Parsing Infrastructure
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â–¡ Set up Tree-sitter with Python, C#, TypeScript, Java grammars
â–¡ Implement BaseParser interface in lfca/semantic/parsing/base.py
â–¡ Create TreeSitterParser generic implementation
â–¡ Write token extraction for class names, methods, properties
â–¡ Add CamelCase/snake_case splitter utility
â–¡ Unit tests for each language parser

Week 2: Token Processing
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â–¡ Implement TokenExtractor service
â–¡ Add lemmatization using spaCy
â–¡ Create TechFilter framework
â–¡ Build .NET technology profile (YAML config)
â–¡ Implement generic programming stopwords list
â–¡ Add token enrichment (synonyms, abbreviations)
â–¡ Integration tests for extraction pipeline

Week 3: Storage & Embeddings
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â–¡ Create SQLite schema for semantic data
â–¡ Implement TokenStore for persistence
â–¡ Build TF-IDF embedder with LSA dimensionality reduction
â–¡ Add embedding caching layer
â–¡ Create SemanticAnalyzer orchestration service
â–¡ CLI command: lfca semantic analyze
â–¡ End-to-end test on sample repository
```

### 9.3 Milestones

| Milestone | Description | Target Date |
|-----------|-------------|-------------|
| **M1: Parser Ready** | Multi-language AST parsing working | Week 1 |
| **M2: Tokens Extracted** | Full extraction pipeline with filtering | Week 2 |
| **M3: First Clusters** | HDBSCAN producing domain clusters | Week 5 |
| **M4: API Live** | REST API for domain discovery | Week 6 |
| **M5: Similarity Search** | Vector-based similarity working | Week 9 |
| **M6: UI Complete** | Full visualization in frontend | Week 12 |
| **M7: Production Ready** | All features, tests, documentation | Week 16 |

---

## 10. Success Metrics

### 10.1 Quality Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Domain Coherence** | >0.75 avg | Silhouette score on embeddings |
| **Classification Accuracy** | >85% | Manual validation on labeled sample |
| **Naming Quality** | >70% acceptable | User survey on auto-generated names |
| **Tech Filter Precision** | >95% | Manual review of filtered tokens |

### 10.2 Performance Metrics

| Metric | Target | Scenario |
|--------|--------|----------|
| **Analysis Time** | <5 min | 10K files, hybrid embedding |
| **Similarity Query** | <100ms | Single file, top-20 results |
| **Classification** | <50ms | Single file |
| **Domain Discovery** | <30s | From cached embeddings |

### 10.3 User Value Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Domain Discovery Adoption** | 60% of users | Usage analytics |
| **Time to Understand Codebase** | -40% | User survey |
| **Refactoring Confidence** | +35% | Developer feedback |
| **Documentation Generated** | 80% of repos | Auto-doc generation |

---

## 11. Appendix

### 11.1 Sample Output: Domain Discovery

```json
{
  "run_id": "sem_20260206_abc123",
  "created_at": "2026-02-06T10:30:00Z",
  "stats": {
    "files_analyzed": 847,
    "tokens_extracted": 34521,
    "domains_found": 8,
    "outlier_files": 23
  },
  "domains": [
    {
      "domain_id": "dom_001",
      "name": "Payment",
      "keywords": ["payment", "charge", "refund", "invoice", "transaction"],
      "file_count": 45,
      "cohesion_score": 0.89,
      "isolation_score": 0.76,
      "subdomains": [
        {
          "domain_id": "dom_001_a",
          "name": "Refund",
          "keywords": ["refund", "reversal", "chargeback"],
          "file_count": 12
        }
      ]
    },
    {
      "domain_id": "dom_002",
      "name": "Authentication",
      "keywords": ["auth", "login", "session", "token", "permission"],
      "file_count": 32,
      "cohesion_score": 0.92,
      "isolation_score": 0.88
    },
    {
      "domain_id": "dom_003",
      "name": "Order",
      "keywords": ["order", "cart", "checkout", "shipping", "item"],
      "file_count": 67,
      "cohesion_score": 0.84,
      "isolation_score": 0.71
    }
  ]
}
```

### 11.2 Sample Output: Classification

```json
{
  "path": "src/Services/OrderPaymentService.cs",
  "primary_domain": {
    "domain_id": "dom_003",
    "name": "Order",
    "affinity": 0.67
  },
  "secondary_domains": [
    {
      "domain_id": "dom_001",
      "name": "Payment",
      "affinity": 0.58
    }
  ],
  "confidence": 0.74,
  "is_outlier": false,
  "reasoning": [
    "Class name contains 'Order' (primary domain keyword)",
    "Class name contains 'Payment' (secondary domain keyword)",
    "Methods reference both order processing and payment handling",
    "Classified as integration point between Order and Payment domains"
  ]
}
```

### 11.3 References

| Resource | Description |
|----------|-------------|
| [Tree-sitter](https://tree-sitter.github.io/) | Multi-language AST parsing |
| [HDBSCAN](https://hdbscan.readthedocs.io/) | Density-based clustering |
| [CodeBERT](https://github.com/microsoft/CodeBERT) | Pre-trained code embeddings |
| [Qdrant](https://qdrant.tech/) | Vector similarity search |
| [spaCy](https://spacy.io/) | Industrial NLP processing |
| [Domain-Driven Design](https://domainlanguage.com/) | Bounded context concepts |

---

*Document Version: 1.0 | Created: February 6, 2026 | Author: LFCA Development Team*
