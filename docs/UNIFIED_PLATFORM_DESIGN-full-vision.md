# Code Intelligence Platform â€” Project-Based Architecture

> **Version**: 2.0  
> **Status**: Design  
> **Created**: 2025  
> **Purpose**: Split LFCA into a multi-project platform with an orchestrator, independent analyzers, and a unified frontend

---

## 1. Executive Summary

The current monolithic `lfca` package is split into **independent projects** that communicate through **well-defined Python interfaces**. An **orchestrator** manages projects, dispatches analysis tasks, and aggregates results. Each **analyzer** (git, dependency, semantic, â€¦) lives in its own project and implements a standard contract. A **project-intelligence** module combines signals from all analyzers to produce unified insights (risk, knowledge graph, cross-source queries).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                         â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                        â”‚    React Frontend     â”‚                         â”‚
â”‚                        â”‚  (single SPA, Vite)   â”‚                         â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                   â”‚ REST                                â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                        â”‚    Orchestrator API   â”‚                         â”‚
â”‚                        â”‚ (CodeIntelPlatform)   â”‚                         â”‚
â”‚                        â””â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”˜                         â”‚
â”‚                           â”‚     â”‚     â”‚   â”‚                             â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚              â–¼                  â–¼     â–¼                   â–¼             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Git Analyzer    â”‚ â”‚ Dep Analyzer   â”‚ â”‚ Semantic       â”‚ â”‚ ...  â”‚  â”‚
â”‚   â”‚  (git-analyzer)  â”‚ â”‚ (dep-analyzer) â”‚ â”‚ (sem-analyzer) â”‚ â”‚      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚              â”‚                  â”‚                 â”‚                      â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â”‚                                 â”‚                                       â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚                        â”‚   Shared DB     â”‚                              â”‚
â”‚                        â”‚   (SQLite)      â”‚                              â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  Project Intelligence (cross-source analysis, risk, knowledge   â”‚   â”‚
â”‚   â”‚  graph)                                                         â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Decisions

| Decision | Choice | Why |
|----------|--------|-----|
| Project separation | Python packages in monorepo | Simple imports, shared virtualenv, single deploy for now |
| Inter-project communication | Direct Python calls via interfaces | No HTTP overhead between analyzers; swap to microservices later if needed |
| Database | Single SQLite per repository | Zero-ops, already proven at scale, all analyzers write to same file |
| Async tasks | Background threads + status in DB | Same pattern that works today, no message broker needed |
| Frontend â†” Backend | REST 1-1 proxy through orchestrator | Frontend never calls analyzers directly |
| No backward compatibility | Clean break | Opportunity to design the right schema and API from scratch |

---

## 2. Project Structure

### 2.1 Monorepo Layout

```
code-intelligence-platform/
â”‚
â”œâ”€â”€ platform/                        # ğŸ¯ ORCHESTRATOR â€” project management & API gateway
â”‚   â”œâ”€â”€ pyproject.toml               #    Package: code-intel-platform
â”‚   â””â”€â”€ code_intel/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ app.py                   # FastAPI app â€” THE single entry point
â”‚       â”œâ”€â”€ config.py                # Global config, RepoPaths, data dirs
â”‚       â”œâ”€â”€ models.py                # Pydantic request/response models (shared)
â”‚       â”œâ”€â”€ storage.py               # DB connection factory, shared access
â”‚       â”œâ”€â”€ schema.py                # Full database DDL (unified schema)
â”‚       â”‚
â”‚       â”œâ”€â”€ routers/                 # FastAPI routers, one per domain
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ repos.py            # CRUD repos, list, delete
â”‚       â”‚   â”œâ”€â”€ analyzers.py        # List/run/status for all analyzers
â”‚       â”‚   â”œâ”€â”€ git.py              # Proxy to git-analyzer API
â”‚       â”‚   â”œâ”€â”€ deps.py             # Proxy to dep-analyzer API
â”‚       â”‚   â”œâ”€â”€ semantic.py         # Proxy to semantic-analyzer API
â”‚       â”‚   â”œâ”€â”€ graph.py            # Unified graph queries (knowledge graph)
â”‚       â”‚   â”œâ”€â”€ risk.py             # Combined risk scoring
â”‚       â”‚   â””â”€â”€ intelligence.py     # Cross-source insights
â”‚       â”‚
â”‚       â”œâ”€â”€ interfaces/             # ğŸ”Œ CONTRACTS â€” analyzers implement these
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ analyzer.py         # BaseAnalyzer ABC + types
â”‚       â”‚   â”œâ”€â”€ git_analyzer.py     # GitAnalyzerInterface (specific to git)
â”‚       â”‚   â”œâ”€â”€ dep_analyzer.py     # DepAnalyzerInterface (specific to deps)
â”‚       â”‚   â”œâ”€â”€ semantic_analyzer.py # SemanticAnalyzerInterface
â”‚       â”‚   â””â”€â”€ types.py            # Shared domain types (Entity, Relationship, etc.)
â”‚       â”‚
â”‚       â”œâ”€â”€ registry.py             # Analyzer discovery & DI container
â”‚       â”œâ”€â”€ orchestrator.py         # Run analysis, combine results, status tracking
â”‚       â””â”€â”€ graph/                  # In-memory graph operations
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ builder.py          # SQLite â†’ NetworkX
â”‚           â”œâ”€â”€ queries.py          # Neighbors, paths, centrality
â”‚           â””â”€â”€ risk.py             # Unified risk model
â”‚
â”œâ”€â”€ git-analyzer/                    # ğŸ“¦ GIT COUPLING ANALYZER
â”‚   â”œâ”€â”€ pyproject.toml               #    Package: git-analyzer
â”‚   â””â”€â”€ git_analyzer/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ plugin.py               # Implements GitAnalyzerInterface â†’ registered
â”‚       â”œâ”€â”€ extract.py              # Git log â†’ parquet (from current lfca/extract.py)
â”‚       â”œâ”€â”€ edges.py                # Pair counting, metrics (from current lfca/edges.py)
â”‚       â”œâ”€â”€ changesets.py           # Changeset grouping (from current lfca/changesets.py)
â”‚       â”œâ”€â”€ git.py                  # Git CLI wrapper (from current lfca/git.py)
â”‚       â”œâ”€â”€ mirror.py              # Bare clone management (from current lfca/mirror.py)
â”‚       â”œâ”€â”€ sync.py                # HEAD sync, file tree (from current lfca/sync.py)
â”‚       â”œâ”€â”€ config.py              # Git-specific config (CouplingConfig)
â”‚       â”‚
â”‚       â”œâ”€â”€ api.py                  # Git-specific query functions (coupling, history, etc.)
â”‚       â”‚                           # Called by orchestrator's git router
â”‚       â”‚
â”‚       â””â”€â”€ clustering/            # Clustering algorithms (from current lfca/clustering/)
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ base.py
â”‚           â”œâ”€â”€ registry.py
â”‚           â”œâ”€â”€ louvain.py
â”‚           â”œâ”€â”€ dbscan.py
â”‚           â”œâ”€â”€ hierarchical.py
â”‚           â”œâ”€â”€ label_propagation.py
â”‚           â”œâ”€â”€ components.py
â”‚           â””â”€â”€ insights.py
â”‚
â”œâ”€â”€ dep-analyzer/                    # ğŸ“¦ DEPENDENCY ANALYZER
â”‚   â”œâ”€â”€ pyproject.toml               #    Package: dep-analyzer
â”‚   â””â”€â”€ dep_analyzer/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ plugin.py               # Implements DepAnalyzerInterface â†’ registered
â”‚       â”œâ”€â”€ analyzer.py             # Orchestrates language parsers
â”‚       â”œâ”€â”€ api.py                  # Dep-specific query functions
â”‚       â”œâ”€â”€ config.py               # Dep-specific config
â”‚       â”‚
â”‚       â””â”€â”€ parsers/                # Language-specific import parsers
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ base.py             # BaseParser ABC
â”‚           â”œâ”€â”€ python_parser.py    # ast module â†’ imports
â”‚           â”œâ”€â”€ typescript_parser.py # Regex â†’ import/require/export
â”‚           â”œâ”€â”€ csharp_parser.py    # Regex â†’ using/csproj
â”‚           â””â”€â”€ java_parser.py      # Regex â†’ imports
â”‚
â”œâ”€â”€ semantic-analyzer/               # ğŸ“¦ SEMANTIC ANALYZER
â”‚   â”œâ”€â”€ pyproject.toml               #    Package: semantic-analyzer
â”‚   â””â”€â”€ semantic_analyzer/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ plugin.py               # Implements SemanticAnalyzerInterface â†’ registered
â”‚       â”œâ”€â”€ analyzer.py             # Orchestrates extraction â†’ embedding â†’ clustering
â”‚       â”œâ”€â”€ api.py                  # Semantic-specific query functions
â”‚       â”œâ”€â”€ config.py               # Semantic-specific config
â”‚       â”‚
â”‚       â”œâ”€â”€ extraction/             # Token extraction
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ tokenizer.py        # CamelCase/snake_case splitting
â”‚       â”‚   â”œâ”€â”€ stopwords.py        # Tech token lists per framework
â”‚       â”‚   â””â”€â”€ extractor.py        # AST/tree-sitter token extraction
â”‚       â”‚
â”‚       â””â”€â”€ embedding/              # Vectorization & similarity
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ tfidf.py            # TF-IDF vectorizer
â”‚           â”œâ”€â”€ similarity.py       # Cosine similarity computation
â”‚           â””â”€â”€ labeler.py          # Auto-generate domain labels
â”‚
â”œâ”€â”€ project-intelligence/            # ğŸ“¦ CROSS-SOURCE INTELLIGENCE
â”‚   â”œâ”€â”€ pyproject.toml               #    Package: project-intelligence
â”‚   â””â”€â”€ project_intel/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ plugin.py               # Registered as a special "meta-analyzer"
â”‚       â”œâ”€â”€ risk_model.py           # Combine signals â†’ unified risk scores
â”‚       â”œâ”€â”€ cross_coupling.py       # Coupling correlation: git â†” deps â†” semantic
â”‚       â”œâ”€â”€ architecture_map.py     # Combine domains + deps â†’ architecture view
â”‚       â””â”€â”€ api.py                  # Intelligence-specific queries
â”‚
â”œâ”€â”€ frontend/                        # ğŸ–¥ï¸ REACT FRONTEND (single SPA)
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ api/                    # API client layer â€” mirrors orchestrator routers
â”‚       â”‚   â”œâ”€â”€ client.ts           # Axios instance + error handling
â”‚       â”‚   â”œâ”€â”€ repos.ts           # /repos endpoints
â”‚       â”‚   â”œâ”€â”€ analyzers.ts       # /analyzers endpoints
â”‚       â”‚   â”œâ”€â”€ git.ts             # /git endpoints (coupling, history, clustering)
â”‚       â”‚   â”œâ”€â”€ deps.ts            # /deps endpoints
â”‚       â”‚   â”œâ”€â”€ semantic.ts        # /semantic endpoints
â”‚       â”‚   â”œâ”€â”€ graph.ts           # /graph endpoints (knowledge graph)
â”‚       â”‚   â”œâ”€â”€ risk.ts            # /risk endpoints
â”‚       â”‚   â””â”€â”€ intelligence.ts    # /intelligence endpoints
â”‚       â”‚
â”‚       â”œâ”€â”€ types/                  # TypeScript types matching backend models
â”‚       â”‚   â”œâ”€â”€ repo.ts
â”‚       â”‚   â”œâ”€â”€ analyzer.ts
â”‚       â”‚   â”œâ”€â”€ git.ts
â”‚       â”‚   â”œâ”€â”€ deps.ts
â”‚       â”‚   â”œâ”€â”€ semantic.ts
â”‚       â”‚   â”œâ”€â”€ graph.ts
â”‚       â”‚   â””â”€â”€ risk.ts
â”‚       â”‚
â”‚       â”œâ”€â”€ features/               # Feature-based component organization
â”‚       â”‚   â”œâ”€â”€ repos/             # Repo list, create, settings
â”‚       â”‚   â”œâ”€â”€ dashboard/         # Enhanced dashboard (all sources)
â”‚       â”‚   â”œâ”€â”€ git/               # Coupling graph, file details, clustering, hotspots
â”‚       â”‚   â”œâ”€â”€ deps/              # Import graph, external deps, circular deps
â”‚       â”‚   â”œâ”€â”€ semantic/          # Domain map, domain detail, bridge files
â”‚       â”‚   â”œâ”€â”€ graph/             # Knowledge graph explorer, path finder
â”‚       â”‚   â”œâ”€â”€ risk/              # Risk overview, treemap, risk table
â”‚       â”‚   â””â”€â”€ intelligence/      # Combined insights, architecture map
â”‚       â”‚
â”‚       â”œâ”€â”€ shared/                 # Shared UI primitives
â”‚       â”œâ”€â”€ hooks/
â”‚       â”œâ”€â”€ stores/
â”‚       â”œâ”€â”€ lib/
â”‚       â”œâ”€â”€ config/
â”‚       â”œâ”€â”€ design-tokens/
â”‚       â”œâ”€â”€ App.tsx
â”‚       â””â”€â”€ main.tsx
â”‚
â”œâ”€â”€ tests/                           # Tests organized by project
â”‚   â”œâ”€â”€ test_platform/
â”‚   â”œâ”€â”€ test_git_analyzer/
â”‚   â”œâ”€â”€ test_dep_analyzer/
â”‚   â”œâ”€â”€ test_semantic_analyzer/
â”‚   â””â”€â”€ test_project_intelligence/
â”‚
â”œâ”€â”€ scripts/                         # Dev utilities
â”œâ”€â”€ docs/
â””â”€â”€ pyproject.toml                   # Root â€” workspace/dev dependencies
```

### 2.2 Package Dependencies

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     DEPENDENCY GRAPH                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚   code-intel-platform (orchestrator)                                    â”‚
â”‚       â”‚                                                                 â”‚
â”‚       â”œâ”€â”€ depends on â†’ git-analyzer                                     â”‚
â”‚       â”œâ”€â”€ depends on â†’ dep-analyzer                                     â”‚
â”‚       â”œâ”€â”€ depends on â†’ semantic-analyzer                                â”‚
â”‚       â”œâ”€â”€ depends on â†’ project-intelligence                             â”‚
â”‚       â”‚                                                                 â”‚
â”‚       â””â”€â”€ OWNS: interfaces/, schema.py, registry.py                    â”‚
â”‚              â†‘                                                          â”‚
â”‚              â”‚ implements                                                â”‚
â”‚              â”‚                                                          â”‚
â”‚   git-analyzer â”€â”€â”                                                      â”‚
â”‚   dep-analyzer â”€â”€â”¤â”€â”€ each imports interfaces from code-intel-platform   â”‚
â”‚   sem-analyzer â”€â”€â”¤   (but only the interfaces/ package, not the app)    â”‚
â”‚   project-intel â”€â”˜                                                      â”‚
â”‚                                                                         â”‚
â”‚   RULE: Analyzers NEVER import each other directly                      â”‚
â”‚   RULE: Analyzers NEVER import platform routers/orchestrator            â”‚
â”‚   RULE: Platform imports analyzer.plugin + analyzer.api only            â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```toml
# platform/pyproject.toml
[project]
name = "code-intel-platform"
dependencies = [
    "fastapi>=0.110.0",
    "uvicorn>=0.27.0",
    "pydantic>=2.6.0",
    "pyarrow>=14.0.0",
    "networkx>=3.0",
    # Analyzer packages (injected at install time)
    "git-analyzer",
    "dep-analyzer",
    "semantic-analyzer",
    "project-intelligence",
]

# git-analyzer/pyproject.toml
[project]
name = "git-analyzer"
dependencies = [
    "pyarrow>=14.0.0",
    "networkx>=3.0",
    "python-louvain>=0.16",
    "scipy>=1.10.0",
    "scikit-learn>=1.3.0",
    "code-intel-platform",     # for interfaces only
]

# dep-analyzer/pyproject.toml
[project]
name = "dep-analyzer"
dependencies = [
    "code-intel-platform",     # for interfaces only
]

# semantic-analyzer/pyproject.toml
[project]
name = "semantic-analyzer"
dependencies = [
    "scikit-learn>=1.3.0",
    "code-intel-platform",     # for interfaces only
]

# project-intelligence/pyproject.toml
[project]
name = "project-intelligence"
dependencies = [
    "networkx>=3.0",
    "code-intel-platform",     # for interfaces only
]
```

> **Circular dependency note**: Platform depends on analyzers, and analyzers depend on platform interfaces. This is resolved by having analyzers import *only* from `code_intel.interfaces` â€” a leaf package with no internal imports. In Python this works with `pip install -e .` in the monorepo. If needed later, extract `code-intel-interfaces` as a standalone package.

---

## 3. Analyzer Interface System

### 3.1 Base Analyzer Contract

Every analyzer implements this interface. The orchestrator uses only this contract â€” never the internal implementation.

```python
# platform/code_intel/interfaces/analyzer.py

from __future__ import annotations
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any


class AnalyzerType(str, Enum):
    """Known analyzer types. Extensible via string values."""
    GIT_COUPLING = "git"
    DEPENDENCY = "deps"
    SEMANTIC = "semantic"
    INTELLIGENCE = "intelligence"


class TaskStatus(str, Enum):
    NOT_RUN = "not_run"
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class AnalysisTask:
    """A unit of work dispatched to an analyzer."""
    task_id: str
    analyzer_type: str
    repo_id: str
    repo_path: Path          # path to mirror.git or source repo
    db_path: Path            # path to the shared SQLite database
    parquet_dir: Path        # path to parquet data directory
    config: dict[str, Any]   # analyzer-specific configuration


@dataclass
class TaskResult:
    """Standard result from any analyzer task."""
    task_id: str
    status: TaskStatus
    entity_count: int = 0
    relationship_count: int = 0
    metrics: dict[str, Any] = field(default_factory=dict)
    error: str | None = None


class BaseAnalyzer(ABC):
    """
    Contract that every analyzer must implement.

    The orchestrator:
    1. Calls list_capabilities() to discover what this analyzer offers
    2. Calls analyze() to run analysis (async-friendly, status tracked in DB)
    3. Calls the analyzer-specific query interface for data retrieval
    """

    @property
    @abstractmethod
    def analyzer_type(self) -> str:
        """Unique identifier: 'git', 'deps', 'semantic', etc."""
        ...

    @property
    @abstractmethod
    def display_name(self) -> str:
        """Human-readable name for UI."""
        ...

    @abstractmethod
    def get_config_schema(self) -> dict:
        """JSON Schema for this analyzer's configuration."""
        ...

    @abstractmethod
    def analyze(self, task: AnalysisTask) -> TaskResult:
        """
        Run analysis. This is the main entry point.

        SYNC tasks: Return TaskResult directly with data.
        ASYNC tasks: Update status in DB, return TaskResult with status=RUNNING,
                     complete work in background.

        The analyzer writes entities and relationships to the shared DB
        using the standard schema.
        """
        ...

    def validate_config(self, config: dict) -> list[str]:
        """Validate configuration. Return list of error messages (empty = valid)."""
        return []
```

### 3.2 Analyzer-Specific Interfaces

Each analyzer type has its own query interface. These are **separate from `BaseAnalyzer`** because query APIs differ fundamentally per analyzer.

```python
# platform/code_intel/interfaces/git_analyzer.py

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Any


class GitAnalyzerAPI(ABC):
    """Query interface specific to git coupling analysis."""

    @abstractmethod
    def get_file_coupling(self, db_path: Path, file_path: str, *,
                          metric: str = "jaccard", min_weight: float = 0.0,
                          limit: int = 50) -> list[dict]:
        """Get files coupled with the given file."""
        ...

    @abstractmethod
    def get_coupling_graph(self, db_path: Path, root_path: str, *,
                           metric: str = "jaccard", min_weight: float = 0.1,
                           limit: int = 200) -> dict:
        """Get coupling graph (nodes + edges) for visualization."""
        ...

    @abstractmethod
    def get_file_history(self, db_path: Path, parquet_dir: Path,
                         file_path: str) -> dict:
        """Get commit history for a file."""
        ...

    @abstractmethod
    def get_file_details(self, db_path: Path, parquet_dir: Path,
                         file_path: str) -> dict:
        """Get comprehensive file details (commits, churn, authors)."""
        ...

    @abstractmethod
    def get_hotspots(self, db_path: Path, parquet_dir: Path, *,
                     limit: int = 50, sort_by: str = "risk_score") -> list[dict]:
        """Get files ranked by risk/churn/coupling."""
        ...

    @abstractmethod
    def get_dashboard_summary(self, db_path: Path, parquet_dir: Path) -> dict:
        """Summary stats for the dashboard."""
        ...

    @abstractmethod
    def get_component_coupling(self, db_path: Path, component: str, *,
                               depth: int = 2) -> list[dict]:
        """Get coupling between components/folders."""
        ...

    @abstractmethod
    def run_clustering(self, db_path: Path, *,
                       algorithm: str = "louvain", weight_column: str = "jaccard",
                       min_weight: float = 0.1, folders: list[str] | None = None,
                       params: dict | None = None) -> dict:
        """Run clustering algorithm on coupling graph."""
        ...

    @abstractmethod
    def get_file_tree(self, db_path: Path) -> dict:
        """Get file tree structure."""
        ...

    @abstractmethod
    def get_authors(self, db_path: Path, parquet_dir: Path, *,
                    limit: int = 50) -> list[dict]:
        """Get author statistics."""
        ...

    @abstractmethod
    def get_timeline(self, db_path: Path, parquet_dir: Path, *,
                     points: int = 12, granularity: str = "monthly") -> list[dict]:
        """Get temporal evolution data."""
        ...
```

```python
# platform/code_intel/interfaces/dep_analyzer.py

from abc import ABC, abstractmethod
from pathlib import Path


class DepAnalyzerAPI(ABC):
    """Query interface specific to dependency analysis."""

    @abstractmethod
    def get_import_graph(self, db_path: Path, *,
                         language: str | None = None,
                         min_imports: int = 1) -> dict:
        """Full import graph (nodes + edges) for visualization."""
        ...

    @abstractmethod
    def get_file_imports(self, db_path: Path, file_path: str) -> dict:
        """What this file imports and what imports this file."""
        ...

    @abstractmethod
    def get_circular_deps(self, db_path: Path) -> list[dict]:
        """Detect circular dependency chains."""
        ...

    @abstractmethod
    def get_external_packages(self, db_path: Path) -> list[dict]:
        """External packages used across codebase."""
        ...

    @abstractmethod
    def get_dependency_stats(self, db_path: Path) -> dict:
        """Summary: total imports, external count, circular count, etc."""
        ...
```

```python
# platform/code_intel/interfaces/semantic_analyzer.py

from abc import ABC, abstractmethod
from pathlib import Path


class SemanticAnalyzerAPI(ABC):
    """Query interface specific to semantic analysis."""

    @abstractmethod
    def get_domains(self, db_path: Path) -> list[dict]:
        """All discovered domains with stats."""
        ...

    @abstractmethod
    def classify_file(self, db_path: Path, file_path: str) -> dict:
        """Which domain(s) does this file belong to?"""
        ...

    @abstractmethod
    def get_similar_files(self, db_path: Path, file_path: str, *,
                          limit: int = 10, min_similarity: float = 0.5) -> list[dict]:
        """Find semantically similar files."""
        ...

    @abstractmethod
    def get_file_tokens(self, db_path: Path, file_path: str) -> dict:
        """Extracted semantic tokens for a file."""
        ...

    @abstractmethod
    def get_domain_detail(self, db_path: Path, domain_id: int) -> dict:
        """Detailed info about a domain: files, terms, cross-coupling."""
        ...

    @abstractmethod
    def get_bridge_entities(self, db_path: Path) -> list[dict]:
        """Entities that span multiple domains."""
        ...
```

### 3.3 Shared Types

```python
# platform/code_intel/interfaces/types.py

from __future__ import annotations
from dataclasses import dataclass, field
from typing import Any


@dataclass
class Entity:
    """A code entity (file, class, function, package)."""
    entity_id: int | None = None
    file_id: int | None = None
    kind: str = "file"              # file, class, function, module, package
    name: str = ""
    qualified_name: str | None = None
    language: str | None = None
    line_start: int | None = None
    line_end: int | None = None
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass
class Relationship:
    """A relationship between two entities."""
    rel_id: int | None = None
    source_type: str = ""           # git, deps, semantic, intelligence
    rel_kind: str = ""              # CO_CHANGED, IMPORTS, SIMILAR_TO, etc.
    src_entity_id: int = 0
    dst_entity_id: int = 0
    weight: float = 1.0
    properties: dict[str, Any] = field(default_factory=dict)
    run_id: str | None = None


@dataclass
class Domain:
    """A semantic domain (cluster of related entities)."""
    domain_id: int | None = None
    label: str = ""
    description: str | None = None
    entity_count: int = 0
    coherence_score: float = 0.0
    top_terms: list[str] = field(default_factory=list)


# Relationship kinds â€” constants
class RelKind:
    # Git analyzer
    CO_CHANGED = "CO_CHANGED"

    # Dependency analyzer
    IMPORTS = "IMPORTS"
    DEPENDS_ON = "DEPENDS_ON"       # external package dependency

    # Semantic analyzer
    SIMILAR_TO = "SIMILAR_TO"
    BELONGS_TO_DOMAIN = "BELONGS_TO_DOMAIN"

    # Future
    CALLS = "CALLS"
    EXTENDS = "EXTENDS"
    IMPLEMENTS = "IMPLEMENTS"
    TESTED_BY = "TESTED_BY"
    OWNS = "OWNS"


# Entity kinds â€” constants
class EntityKind:
    FILE = "file"
    CLASS = "class"
    FUNCTION = "function"
    MODULE = "module"
    PACKAGE = "package"
    EXTERNAL_PACKAGE = "external_package"
```

### 3.4 Analyzer Registry & Dependency Injection

```python
# platform/code_intel/registry.py

from __future__ import annotations
from typing import Any
from code_intel.interfaces.analyzer import BaseAnalyzer
from code_intel.interfaces.git_analyzer import GitAnalyzerAPI
from code_intel.interfaces.dep_analyzer import DepAnalyzerAPI
from code_intel.interfaces.semantic_analyzer import SemanticAnalyzerAPI


class AnalyzerRegistry:
    """
    Central registry. Analyzers register themselves at import time.
    The orchestrator uses this to discover and dispatch to analyzers.
    """

    def __init__(self):
        self._analyzers: dict[str, BaseAnalyzer] = {}
        self._apis: dict[str, Any] = {}     # analyzer_type â†’ API impl

    def register(self, analyzer: BaseAnalyzer, api: Any = None):
        """Register an analyzer and its query API."""
        self._analyzers[analyzer.analyzer_type] = analyzer
        if api is not None:
            self._apis[analyzer.analyzer_type] = api

    def get_analyzer(self, analyzer_type: str) -> BaseAnalyzer:
        if analyzer_type not in self._analyzers:
            raise ValueError(f"Unknown analyzer: {analyzer_type}. "
                           f"Available: {list(self._analyzers.keys())}")
        return self._analyzers[analyzer_type]

    def get_api(self, analyzer_type: str) -> Any:
        """Get the query API for an analyzer type."""
        if analyzer_type not in self._apis:
            raise ValueError(f"No API registered for: {analyzer_type}")
        return self._apis[analyzer_type]

    def get_git_api(self) -> GitAnalyzerAPI:
        return self._apis["git"]

    def get_dep_api(self) -> DepAnalyzerAPI:
        return self._apis["deps"]

    def get_semantic_api(self) -> SemanticAnalyzerAPI:
        return self._apis["semantic"]

    def list_all(self) -> list[dict]:
        return [
            {
                "type": a.analyzer_type,
                "display_name": a.display_name,
                "config_schema": a.get_config_schema(),
            }
            for a in self._analyzers.values()
        ]


# Global singleton
registry = AnalyzerRegistry()
```

```python
# platform/code_intel/app.py â€” Startup wiring

from code_intel.registry import registry

def register_analyzers():
    """
    Import and register all analyzer plugins.
    Each analyzer's plugin.py calls registry.register() on import.
    """
    # Git analyzer
    from git_analyzer.plugin import GitPlugin, GitAPI
    registry.register(GitPlugin(), GitAPI())

    # Dep analyzer
    from dep_analyzer.plugin import DepPlugin, DepAPI
    registry.register(DepPlugin(), DepAPI())

    # Semantic analyzer
    from semantic_analyzer.plugin import SemanticPlugin, SemanticAPI
    registry.register(SemanticPlugin(), SemanticAPI())

    # Project intelligence
    from project_intel.plugin import IntelPlugin, IntelAPI
    registry.register(IntelPlugin(), IntelAPI())
```

### 3.5 Example: Git Analyzer Plugin

```python
# git-analyzer/git_analyzer/plugin.py

from code_intel.interfaces.analyzer import BaseAnalyzer, AnalysisTask, TaskResult, TaskStatus
from code_intel.interfaces.git_analyzer import GitAnalyzerAPI
from pathlib import Path


class GitPlugin(BaseAnalyzer):
    """Git coupling analyzer â€” wraps the existing extraction pipeline."""

    @property
    def analyzer_type(self) -> str:
        return "git"

    @property
    def display_name(self) -> str:
        return "Git Coupling Analysis"

    def get_config_schema(self) -> dict:
        return {
            "type": "object",
            "properties": {
                "min_revisions": {"type": "integer", "default": 5},
                "max_changeset_size": {"type": "integer", "default": 50},
                "changeset_mode": {
                    "type": "string",
                    "enum": ["by_commit", "by_author_time", "by_ticket_id"],
                },
                "min_cooccurrence": {"type": "integer", "default": 5},
                "window_days": {"type": "integer", "nullable": True},
                "since": {"type": "string", "nullable": True},
                "until": {"type": "string", "nullable": True},
            }
        }

    def analyze(self, task: AnalysisTask) -> TaskResult:
        """Run the full git analysis pipeline."""
        from git_analyzer.extract import HistoryExtractor
        from git_analyzer.edges import EdgeBuilder
        from git_analyzer.mirror import mirror_repo
        from git_analyzer.config import CouplingConfig

        # Delegates to existing pipeline, writes to shared DB
        # 1. mirror_repo(task.repo_path, task.config)
        # 2. HistoryExtractor(...).run() â†’ parquet
        # 3. EdgeBuilder(...).build() â†’ git_edges + relationships
        # 4. Return TaskResult
        pass


class GitAPI(GitAnalyzerAPI):
    """Query implementation for git data."""

    def get_file_coupling(self, db_path, file_path, *, metric="jaccard",
                          min_weight=0.0, limit=50):
        # Query git_edges table
        ...

    def get_coupling_graph(self, db_path, root_path, *, metric="jaccard",
                           min_weight=0.1, limit=200):
        ...

    # ... all other methods from GitAnalyzerAPI ...
```

---

## 4. Database Schema

### 4.1 Design Principles

- **Single SQLite file per repository** at `data/repos/{repo_id}/code-intel.sqlite`
- **All analyzers write to the same DB** â€” the schema is owned by the platform
- **Analyzer-specific tables are allowed** (prefixed: `git_`, `dep_`, `sem_`) for data that doesn't fit the unified model
- **Parquet for bulk data** (commit history, changes) â€” same directory `data/repos/{repo_id}/parquet/`

### 4.2 Complete Schema

```sql
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
-- CODE INTELLIGENCE PLATFORM â€” UNIFIED DATABASE SCHEMA
-- â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PRAGMA journal_mode = WAL;
PRAGMA synchronous = NORMAL;
PRAGMA foreign_keys = ON;

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- CORE: Repository & Project Management
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE IF NOT EXISTS repo_meta (
    key   TEXT PRIMARY KEY,
    value TEXT
);

CREATE TABLE IF NOT EXISTS schema_info (
    key   TEXT PRIMARY KEY,
    value TEXT
);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- CORE: Code Entities (files, classes, functions, packages)
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE IF NOT EXISTS entities (
    entity_id       INTEGER PRIMARY KEY AUTOINCREMENT,
    kind            TEXT NOT NULL,           -- 'file','class','function','module','package','external_package'
    name            TEXT NOT NULL,           -- short name
    qualified_name  TEXT,                    -- full path or qualified name (unique for files)
    language        TEXT,                    -- 'python','typescript','csharp','java'
    parent_id       INTEGER REFERENCES entities(entity_id),  -- file for class, class for method
    line_start      INTEGER,
    line_end        INTEGER,
    exists_at_head  BOOLEAN DEFAULT TRUE,
    metadata_json   TEXT,                    -- extensible (LOC, complexity, etc.)
    created_at      TEXT DEFAULT CURRENT_TIMESTAMP,
    updated_at      TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE UNIQUE INDEX IF NOT EXISTS idx_entities_qualified
    ON entities(qualified_name) WHERE qualified_name IS NOT NULL;
CREATE INDEX IF NOT EXISTS idx_entities_kind ON entities(kind);
CREATE INDEX IF NOT EXISTS idx_entities_name ON entities(name);
CREATE INDEX IF NOT EXISTS idx_entities_parent ON entities(parent_id);
CREATE INDEX IF NOT EXISTS idx_entities_language ON entities(language);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- CORE: Relationships (unified edges â€” ALL source types)
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE IF NOT EXISTS relationships (
    rel_id          INTEGER PRIMARY KEY AUTOINCREMENT,
    source_type     TEXT NOT NULL,           -- 'git','deps','semantic','intelligence'
    rel_kind        TEXT NOT NULL,           -- 'CO_CHANGED','IMPORTS','SIMILAR_TO', etc.
    src_entity_id   INTEGER NOT NULL REFERENCES entities(entity_id),
    dst_entity_id   INTEGER NOT NULL REFERENCES entities(entity_id),
    weight          REAL DEFAULT 1.0,
    properties_json TEXT,                    -- source-specific extra data
    run_id          TEXT,
    created_at      TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_rel_source ON relationships(source_type);
CREATE INDEX IF NOT EXISTS idx_rel_kind ON relationships(rel_kind);
CREATE INDEX IF NOT EXISTS idx_rel_src ON relationships(src_entity_id);
CREATE INDEX IF NOT EXISTS idx_rel_dst ON relationships(dst_entity_id);
CREATE INDEX IF NOT EXISTS idx_rel_weight ON relationships(weight DESC);
CREATE INDEX IF NOT EXISTS idx_rel_kind_src ON relationships(rel_kind, src_entity_id);
CREATE INDEX IF NOT EXISTS idx_rel_src_source ON relationships(src_entity_id, source_type);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- CORE: Analysis Task Tracking
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE IF NOT EXISTS analysis_tasks (
    task_id         TEXT PRIMARY KEY,
    analyzer_type   TEXT NOT NULL,
    state           TEXT NOT NULL DEFAULT 'pending',  -- pending/running/completed/failed
    config_json     TEXT,
    progress        REAL DEFAULT 0.0,        -- 0.0 to 1.0
    stage           TEXT,                    -- human-readable stage description
    entity_count    INTEGER DEFAULT 0,
    relationship_count INTEGER DEFAULT 0,
    metrics_json    TEXT,                     -- analyzer-specific result metrics
    started_at      TEXT,
    finished_at     TEXT,
    error           TEXT,
    created_at      TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_tasks_type ON analysis_tasks(analyzer_type);
CREATE INDEX IF NOT EXISTS idx_tasks_state ON analysis_tasks(state);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- GIT ANALYZER: Specific tables (prefixed git_)
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

-- File path history (renames/moves tracked by git analyzer)
CREATE TABLE IF NOT EXISTS git_file_lineage (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    entity_id       INTEGER NOT NULL REFERENCES entities(entity_id),
    path            TEXT NOT NULL,
    start_commit_oid TEXT NOT NULL,
    end_commit_oid  TEXT,
    UNIQUE(entity_id, path, start_commit_oid)
);
CREATE INDEX IF NOT EXISTS idx_git_lineage_entity ON git_file_lineage(entity_id);

-- Git coupling edges (fast path for coupling-specific queries)
-- Duplicates relationship data but optimized for the coupling UI
CREATE TABLE IF NOT EXISTS git_edges (
    src_entity_id   INTEGER NOT NULL REFERENCES entities(entity_id),
    dst_entity_id   INTEGER NOT NULL REFERENCES entities(entity_id),
    pair_count      REAL NOT NULL,
    src_count       INTEGER NOT NULL,
    dst_count       INTEGER NOT NULL,
    src_weight      REAL NOT NULL,
    dst_weight      REAL NOT NULL,
    jaccard         REAL NOT NULL,
    jaccard_weighted REAL NOT NULL,
    p_dst_given_src REAL NOT NULL,
    p_src_given_dst REAL NOT NULL,
    PRIMARY KEY (src_entity_id, dst_entity_id)
);
CREATE INDEX IF NOT EXISTS idx_git_edges_src ON git_edges(src_entity_id);
CREATE INDEX IF NOT EXISTS idx_git_edges_dst ON git_edges(dst_entity_id);
CREATE INDEX IF NOT EXISTS idx_git_edges_jaccard ON git_edges(jaccard DESC);

-- Component-level coupling
CREATE TABLE IF NOT EXISTS git_component_edges (
    src_component   TEXT NOT NULL,
    dst_component   TEXT NOT NULL,
    depth           INTEGER NOT NULL,
    pair_count      REAL NOT NULL,
    jaccard         REAL NOT NULL,
    file_pair_count INTEGER NOT NULL,
    PRIMARY KEY (src_component, dst_component, depth)
);

-- Clustering runs and results
CREATE TABLE IF NOT EXISTS git_cluster_runs (
    cluster_run_id  TEXT PRIMARY KEY,
    task_id         TEXT REFERENCES analysis_tasks(task_id),
    algorithm       TEXT NOT NULL,
    parameters_json TEXT,
    cluster_count   INTEGER,
    modularity      REAL,
    state           TEXT DEFAULT 'pending',
    created_at      TEXT DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS git_clusters (
    cluster_run_id  TEXT NOT NULL REFERENCES git_cluster_runs(cluster_run_id),
    cluster_id      INTEGER NOT NULL,
    entity_id       INTEGER NOT NULL REFERENCES entities(entity_id),
    PRIMARY KEY (cluster_run_id, cluster_id, entity_id)
);
CREATE INDEX IF NOT EXISTS idx_git_clusters_run ON git_clusters(cluster_run_id);

-- Clustering snapshots (saved results)
CREATE TABLE IF NOT EXISTS git_cluster_snapshots (
    snapshot_id     TEXT PRIMARY KEY,
    name            TEXT NOT NULL,
    algorithm       TEXT NOT NULL,
    result_json     TEXT NOT NULL,
    tags_json       TEXT,
    created_at      TEXT DEFAULT CURRENT_TIMESTAMP
);

-- Validation log
CREATE TABLE IF NOT EXISTS git_validation_log (
    id              INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id         TEXT NOT NULL,
    commit_oid      TEXT,
    issue_type      TEXT NOT NULL,
    severity        TEXT NOT NULL,
    token_value     TEXT,
    expected_value  TEXT,
    message         TEXT NOT NULL,
    author          TEXT,
    committed_at    INTEGER,
    subject         TEXT,
    cursor_position INTEGER,
    created_at      TEXT DEFAULT CURRENT_TIMESTAMP
);
CREATE INDEX IF NOT EXISTS idx_git_validation_task ON git_validation_log(task_id);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- DEPENDENCY ANALYZER: Specific tables (prefixed dep_)
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

-- Import detail (richer than generic relationship)
CREATE TABLE IF NOT EXISTS dep_imports (
    import_id       INTEGER PRIMARY KEY AUTOINCREMENT,
    src_entity_id   INTEGER NOT NULL REFERENCES entities(entity_id),
    dst_entity_id   INTEGER NOT NULL REFERENCES entities(entity_id),
    import_type     TEXT NOT NULL,       -- 'internal','external','stdlib'
    symbols_json    TEXT,                -- ["Class1", "func2"] or NULL for wildcard
    line_number     INTEGER,
    is_dynamic      BOOLEAN DEFAULT FALSE
);
CREATE INDEX IF NOT EXISTS idx_dep_imports_src ON dep_imports(src_entity_id);
CREATE INDEX IF NOT EXISTS idx_dep_imports_dst ON dep_imports(dst_entity_id);
CREATE INDEX IF NOT EXISTS idx_dep_imports_type ON dep_imports(import_type);

-- Detected circular dependency cycles
CREATE TABLE IF NOT EXISTS dep_cycles (
    cycle_id        INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id         TEXT NOT NULL,
    chain_json      TEXT NOT NULL,       -- ["file_a.py", "file_b.py", "file_a.py"]
    length          INTEGER NOT NULL,
    severity        TEXT DEFAULT 'warning',
    created_at      TEXT DEFAULT CURRENT_TIMESTAMP
);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- SEMANTIC ANALYZER: Specific tables (prefixed sem_)
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

-- Extracted tokens per entity
CREATE TABLE IF NOT EXISTS sem_tokens (
    token_id        INTEGER PRIMARY KEY AUTOINCREMENT,
    entity_id       INTEGER NOT NULL REFERENCES entities(entity_id),
    token           TEXT NOT NULL,
    token_type      TEXT,                -- 'class_name','method_name','variable','comment'
    tf_idf          REAL,
    is_business     BOOLEAN DEFAULT TRUE
);
CREATE INDEX IF NOT EXISTS idx_sem_tokens_entity ON sem_tokens(entity_id);
CREATE INDEX IF NOT EXISTS idx_sem_tokens_token ON sem_tokens(token);

-- Discovered domains
CREATE TABLE IF NOT EXISTS sem_domains (
    domain_id       INTEGER PRIMARY KEY AUTOINCREMENT,
    task_id         TEXT NOT NULL,
    label           TEXT NOT NULL,
    description     TEXT,
    entity_count    INTEGER DEFAULT 0,
    coherence_score REAL,
    top_terms_json  TEXT,               -- ["payment","invoice","billing"]
    created_at      TEXT DEFAULT CURRENT_TIMESTAMP
);

-- Domain membership
CREATE TABLE IF NOT EXISTS sem_domain_members (
    domain_id       INTEGER NOT NULL REFERENCES sem_domains(domain_id),
    entity_id       INTEGER NOT NULL REFERENCES entities(entity_id),
    affinity        REAL NOT NULL,       -- 0.0-1.0
    PRIMARY KEY (domain_id, entity_id)
);
CREATE INDEX IF NOT EXISTS idx_sem_members_entity ON sem_domain_members(entity_id);

-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
-- INTELLIGENCE: Risk scores (computed from all sources)
-- â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CREATE TABLE IF NOT EXISTS intel_risk_scores (
    entity_id       INTEGER NOT NULL REFERENCES entities(entity_id),
    task_id         TEXT NOT NULL,
    overall_risk    REAL NOT NULL,       -- 0.0-10.0
    coupling_risk   REAL DEFAULT 0.0,
    dependency_risk REAL DEFAULT 0.0,
    churn_risk      REAL DEFAULT 0.0,
    semantic_risk   REAL DEFAULT 0.0,
    signals_json    TEXT,               -- detailed signal list
    computed_at     TEXT DEFAULT CURRENT_TIMESTAMP,
    PRIMARY KEY (entity_id, task_id)
);
CREATE INDEX IF NOT EXISTS idx_risk_overall ON intel_risk_scores(overall_risk DESC);
```

### 4.3 Entity Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ENTITY LIFECYCLE                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  Git Analyzer runs first:                                           â”‚
â”‚    â†’ Creates entities for every file (kind='file')                  â”‚
â”‚    â†’ qualified_name = file path                                     â”‚
â”‚    â†’ Writes git_edges + relationships (CO_CHANGED)                  â”‚
â”‚                                                                     â”‚
â”‚  Dep Analyzer runs second:                                          â”‚
â”‚    â†’ Reuses existing file entities (lookup by qualified_name)       â”‚
â”‚    â†’ Creates new entities for external packages (kind='external')   â”‚
â”‚    â†’ Creates entities for classes/functions if parsed               â”‚
â”‚    â†’ Writes dep_imports + relationships (IMPORTS, DEPENDS_ON)       â”‚
â”‚                                                                     â”‚
â”‚  Semantic Analyzer runs third:                                      â”‚
â”‚    â†’ Reuses existing entities                                       â”‚
â”‚    â†’ Writes sem_tokens per entity                                   â”‚
â”‚    â†’ Writes relationships (SIMILAR_TO)                              â”‚
â”‚    â†’ Creates sem_domains + sem_domain_members                       â”‚
â”‚                                                                     â”‚
â”‚  Intelligence runs last:                                            â”‚
â”‚    â†’ Reads all relationships                                        â”‚
â”‚    â†’ Computes intel_risk_scores                                     â”‚
â”‚    â†’ Writes cross-source relationships                              â”‚
â”‚                                                                     â”‚
â”‚  Key rule: get_or_create_entity(qualified_name, kind)               â”‚
â”‚    â†’ If exists, return entity_id                                    â”‚
â”‚    â†’ If not, INSERT and return entity_id                            â”‚
â”‚    â†’ This prevents duplication across analyzers                     â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. API Design

### 5.1 Router Structure

The orchestrator exposes a single FastAPI app. Each router maps to a feature domain. Routers **proxy** to analyzer APIs â€” they do not contain business logic.

```
app.py
  â”œâ”€â”€ /repos                        â†’ routers/repos.py         (orchestrator owns)
  â”œâ”€â”€ /repos/{id}/analyzers         â†’ routers/analyzers.py     (orchestrator owns)
  â”œâ”€â”€ /repos/{id}/git/...           â†’ routers/git.py           (proxies to GitAPI)
  â”œâ”€â”€ /repos/{id}/deps/...          â†’ routers/deps.py          (proxies to DepAPI)
  â”œâ”€â”€ /repos/{id}/semantic/...      â†’ routers/semantic.py      (proxies to SemanticAPI)
  â”œâ”€â”€ /repos/{id}/graph/...         â†’ routers/graph.py         (orchestrator: NetworkX)
  â”œâ”€â”€ /repos/{id}/risk/...          â†’ routers/risk.py          (proxies to IntelAPI)
  â””â”€â”€ /repos/{id}/intelligence/...  â†’ routers/intelligence.py  (proxies to IntelAPI)
```

### 5.2 Full Endpoint Catalog

```
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
REPOS (orchestrator owns)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GET    /repos                              List all repositories
POST   /repos                              Create repository
DELETE /repos/{repo_id}                    Delete repository
GET    /repos/{repo_id}                    Get repo details

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ANALYZERS (orchestrator owns, dispatches to plugins)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GET    /repos/{repo_id}/analyzers                      List available analyzers + status
POST   /repos/{repo_id}/analyzers/{type}/run           Start an analyzer (async â†’ task_id)
GET    /repos/{repo_id}/analyzers/{type}/status         Get latest task status
GET    /repos/{repo_id}/analyzers/tasks                All tasks history
GET    /repos/{repo_id}/analyzers/tasks/{task_id}      Specific task detail

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GIT (proxy to git-analyzer API)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GET    /repos/{repo_id}/git/files/tree                 File tree
GET    /repos/{repo_id}/git/files                      List files (search, filter)
GET    /repos/{repo_id}/git/files/{path}/details       File details (churn, authors, etc.)
GET    /repos/{repo_id}/git/files/{path}/history       Commit history for file
GET    /repos/{repo_id}/git/files/{path}/lineage       Rename/move history
GET    /repos/{repo_id}/git/files/{path}/activity      Activity charts data
GET    /repos/{repo_id}/git/files/{path}/authors       Author breakdown for file
GET    /repos/{repo_id}/git/files/{path}/commits       Commit list for file
GET    /repos/{repo_id}/git/folders/{path}/details     Folder-level stats
GET    /repos/{repo_id}/git/folders                    List folders

GET    /repos/{repo_id}/git/coupling                   Coupled files for a path
GET    /repos/{repo_id}/git/coupling/graph             Coupling graph (nodes+edges)
GET    /repos/{repo_id}/git/coupling/evidence          Commits where pair co-changed
GET    /repos/{repo_id}/git/coupling/components        Component-level coupling
GET    /repos/{repo_id}/git/coupling/edges             Raw coupling edges (export)

GET    /repos/{repo_id}/git/hotspots                   Files ranked by risk
GET    /repos/{repo_id}/git/authors                    Author statistics
GET    /repos/{repo_id}/git/dashboard                  Summary stats
GET    /repos/{repo_id}/git/trends                     Trend data over time
GET    /repos/{repo_id}/git/timeline                   Timeline evolution

POST   /repos/{repo_id}/git/clustering/run             Run clustering algorithm
GET    /repos/{repo_id}/git/clustering/algorithms      List clustering algorithms
GET    /repos/{repo_id}/git/clustering/snapshots       List saved snapshots
POST   /repos/{repo_id}/git/clustering/snapshots       Save snapshot
GET    /repos/{repo_id}/git/clustering/snapshots/{id}  Get snapshot
PUT    /repos/{repo_id}/git/clustering/snapshots/{id}  Update snapshot
DELETE /repos/{repo_id}/git/clustering/snapshots/{id}  Delete snapshot
GET    /repos/{repo_id}/git/clustering/snapshots/{id}/edges  Snapshot edges
GET    /repos/{repo_id}/git/clustering/compare         Compare two snapshots

GET    /repos/{repo_id}/git/validation/stats           Validation statistics
GET    /repos/{repo_id}/git/validation/log             Validation log entries

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEPS (proxy to dep-analyzer API)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GET    /repos/{repo_id}/deps/graph                     Import graph (nodes+edges)
GET    /repos/{repo_id}/deps/files/{path}/imports      What file imports / imported by
GET    /repos/{repo_id}/deps/circular                  Circular dependency chains
GET    /repos/{repo_id}/deps/external                  External packages used
GET    /repos/{repo_id}/deps/stats                     Summary statistics

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SEMANTIC (proxy to semantic-analyzer API)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GET    /repos/{repo_id}/semantic/domains               All discovered domains
GET    /repos/{repo_id}/semantic/domains/{id}          Domain detail
GET    /repos/{repo_id}/semantic/files/{path}/classify  Domain classification for file
GET    /repos/{repo_id}/semantic/files/{path}/similar   Semantically similar files
GET    /repos/{repo_id}/semantic/files/{path}/tokens    Extracted tokens for file
GET    /repos/{repo_id}/semantic/bridges               Bridge entities (multi-domain)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GRAPH (orchestrator owns â€” queries unified relationships table)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GET    /repos/{repo_id}/graph/entities                 Search/filter entities
GET    /repos/{repo_id}/graph/entities/{id}            Entity detail with all signals
GET    /repos/{repo_id}/graph/relationships            Query relationships
GET    /repos/{repo_id}/graph/neighbors/{entity_id}    Neighborhood subgraph
GET    /repos/{repo_id}/graph/path                     Shortest path between entities
GET    /repos/{repo_id}/graph/stats                    Graph-level stats (centrality etc.)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RISK & INTELLIGENCE (proxy to project-intelligence API)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GET    /repos/{repo_id}/risk/overview                  Overall risk scorecard
GET    /repos/{repo_id}/risk/files                     Per-file risk scores
GET    /repos/{repo_id}/risk/folders                   Per-folder risk aggregation

GET    /repos/{repo_id}/intelligence/dashboard         Combined dashboard from all sources
GET    /repos/{repo_id}/intelligence/architecture      Architecture map (domains + deps)
GET    /repos/{repo_id}/intelligence/correlations      Coupling correlation across sources
```

### 5.3 Sync vs Async Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SYNC vs ASYNC                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  ASYNC (long-running â†’ status in DB):                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                              â”‚
â”‚  POST /repos/{id}/analyzers/{type}/run                              â”‚
â”‚    â†’ Returns { task_id, status: "pending" }                         â”‚
â”‚    â†’ Analyzer runs in BackgroundTask                                â”‚
â”‚    â†’ Updates analysis_tasks row: progress, stage, state             â”‚
â”‚    â†’ Frontend polls GET /repos/{id}/analyzers/{type}/status         â”‚
â”‚                                                                     â”‚
â”‚  POST /repos/{id}/git/clustering/run                                â”‚
â”‚    â†’ Returns { task_id, status: "pending" }                         â”‚
â”‚    â†’ Clustering runs in background (can be slow for large graphs)   â”‚
â”‚    â†’ Frontend polls until completed, then fetches result            â”‚
â”‚                                                                     â”‚
â”‚  SYNC (fast queries â†’ immediate response):                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚  All GET endpoints                                                  â”‚
â”‚    â†’ Direct DB queries                                              â”‚
â”‚    â†’ Return data immediately                                        â”‚
â”‚    â†’ Some may use in-memory caching (graph builder)                 â”‚
â”‚                                                                     â”‚
â”‚  Pattern for async:                                                 â”‚
â”‚    1. POST â†’ create task row (pending) â†’ start background job       â”‚
â”‚    2. Background job: update state=running, progress=0.3, ...       â”‚
â”‚    3. On complete: state=completed, store results                   â”‚
â”‚    4. On error: state=failed, store error message                   â”‚
â”‚    5. GET status â†’ read task row â†’ return current state             â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.4 Router Implementation Pattern

```python
# platform/code_intel/routers/git.py

from fastapi import APIRouter, Depends, Query
from code_intel.registry import registry
from code_intel.config import get_repo_paths

router = APIRouter(prefix="/repos/{repo_id}/git", tags=["git"])


@router.get("/coupling")
def get_coupling(
    repo_id: str,
    path: str = Query(...),
    metric: str = Query("jaccard"),
    min_weight: float = Query(0.0),
    limit: int = Query(50),
):
    """Proxy to git-analyzer's coupling query."""
    paths = get_repo_paths(repo_id)
    api = registry.get_git_api()
    return api.get_file_coupling(
        paths.db_path, path,
        metric=metric, min_weight=min_weight, limit=limit,
    )


@router.get("/coupling/graph")
def get_coupling_graph(
    repo_id: str,
    path: str = Query(...),
    metric: str = Query("jaccard"),
    min_weight: float = Query(0.1),
    limit: int = Query(200),
):
    paths = get_repo_paths(repo_id)
    api = registry.get_git_api()
    return api.get_coupling_graph(
        paths.db_path, path,
        metric=metric, min_weight=min_weight, limit=limit,
    )


# ... same pattern for all git endpoints ...
```

---

## 6. Frontend Architecture

### 6.1 Design Principles

1. **Feature-based organization** â€” each analyzer gets its own feature folder
2. **API 1-1 proxy** â€” `frontend/src/api/git.ts` maps exactly to `/repos/{id}/git/*` endpoints
3. **Shared components** â€” UI primitives reused across all features
4. **Cross-linking** â€” any file name or entity is clickable, navigates to detail view

### 6.2 Information Architecture & Routes

```
/                                          â†’ Redirect to /repos
/repos                                     â†’ RepoList
/repos/:id                                â†’ Redirect to /repos/:id/dashboard
/repos/:id/dashboard                       â†’ IntelligenceDashboard (combined)
/repos/:id/git                             â†’ Redirect to /repos/:id/git/coupling
/repos/:id/git/coupling                    â†’ CouplingGraph
/repos/:id/git/files                       â†’ FileTree
/repos/:id/git/files/:path                 â†’ FileDetail
/repos/:id/git/folders/:path               â†’ FolderDetail
/repos/:id/git/hotspots                    â†’ HotspotsView
/repos/:id/git/clustering                  â†’ ClusteringWorkspace
/repos/:id/git/timeline                    â†’ TimeMachine
/repos/:id/git/authors                     â†’ AuthorStats
/repos/:id/deps                            â†’ Redirect to /repos/:id/deps/graph
/repos/:id/deps/graph                      â†’ ImportGraph
/repos/:id/deps/external                   â†’ ExternalPackages
/repos/:id/deps/circular                   â†’ CircularDeps
/repos/:id/deps/files/:path                â†’ FileImportDetail
/repos/:id/semantic                        â†’ Redirect to /repos/:id/semantic/domains
/repos/:id/semantic/domains                â†’ DomainMap
/repos/:id/semantic/domains/:id            â†’ DomainDetail
/repos/:id/semantic/files/:path            â†’ FileSemanticDetail
/repos/:id/semantic/bridges                â†’ BridgeEntities
/repos/:id/graph                           â†’ KnowledgeGraphExplorer
/repos/:id/graph/entities/:id              â†’ EntityDetail (all signals)
/repos/:id/risk                            â†’ RiskOverview
/repos/:id/risk/files                      â†’ RiskFileTable
/repos/:id/risk/folders                    â†’ RiskTreemap
/repos/:id/settings                        â†’ AnalyzerSettings (configs + run)
```

### 6.3 Frontend Component Tree

```
frontend/src/
â”‚
â”œâ”€â”€ api/                              # 1-1 mapping to backend routers
â”‚   â”œâ”€â”€ client.ts                     # Axios instance, interceptors, error types
â”‚   â”œâ”€â”€ repos.ts                      # getRepos, createRepo, deleteRepo
â”‚   â”œâ”€â”€ analyzers.ts                  # listAnalyzers, runAnalyzer, getStatus
â”‚   â”œâ”€â”€ git.ts                        # getCoupling, getCouplingGraph, getHotspots, ...
â”‚   â”œâ”€â”€ deps.ts                       # getImportGraph, getCircularDeps, ...
â”‚   â”œâ”€â”€ semantic.ts                   # getDomains, classifyFile, getSimilar, ...
â”‚   â”œâ”€â”€ graph.ts                      # getEntities, getNeighbors, getPath, ...
â”‚   â”œâ”€â”€ risk.ts                       # getRiskOverview, getRiskFiles, ...
â”‚   â””â”€â”€ intelligence.ts               # getDashboard, getArchitecture, ...
â”‚
â”œâ”€â”€ types/                            # TypeScript types (mirrors backend models)
â”‚   â”œâ”€â”€ repo.ts                       # RepoInfo
â”‚   â”œâ”€â”€ analyzer.ts                   # AnalyzerInfo, TaskStatus, TaskResult
â”‚   â”œâ”€â”€ entity.ts                     # Entity, Relationship, RelKind
â”‚   â”œâ”€â”€ git.ts                        # CoupledFile, ClusterResult, HotspotFile, etc.
â”‚   â”œâ”€â”€ deps.ts                       # ImportInfo, CircularDep, ExternalPackage
â”‚   â”œâ”€â”€ semantic.ts                   # Domain, DomainMember, SemanticToken
â”‚   â”œâ”€â”€ graph.ts                      # GraphNode, GraphEdge, PathResult
â”‚   â””â”€â”€ risk.ts                       # RiskScore, RiskSignal
â”‚
â”œâ”€â”€ features/                         # Feature modules (1 per concern)
â”‚   â”‚
â”‚   â”œâ”€â”€ repos/                        # Repository management
â”‚   â”‚   â”œâ”€â”€ RepoList.tsx
â”‚   â”‚   â”œâ”€â”€ RepoCard.tsx
â”‚   â”‚   â”œâ”€â”€ CreateRepoModal.tsx
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ dashboard/                    # Combined intelligence dashboard
â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx             # Main layout with widget grid
â”‚   â”‚   â”œâ”€â”€ StatCards.tsx             # Top-level metrics (files, commits, risk, ...)
â”‚   â”‚   â”œâ”€â”€ AnalyzerStatusPanel.tsx   # Run status for each analyzer
â”‚   â”‚   â”œâ”€â”€ RiskSignalsWidget.tsx     # Top risk files mini-list
â”‚   â”‚   â”œâ”€â”€ DomainOverviewWidget.tsx  # Domain summary mini-chart
â”‚   â”‚   â”œâ”€â”€ TrendChart.tsx            # Multi-line area chart
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ git/                          # Git coupling features
â”‚   â”‚   â”œâ”€â”€ CouplingGraph.tsx         # D3 force-directed coupling graph
â”‚   â”‚   â”œâ”€â”€ FileTree.tsx              # Folder tree explorer
â”‚   â”‚   â”œâ”€â”€ FileDetail.tsx            # Comprehensive file detail panel
â”‚   â”‚   â”œâ”€â”€ FolderDetail.tsx          # Folder-level stats
â”‚   â”‚   â”œâ”€â”€ HotspotsView.tsx         # Hotspot table/chart
â”‚   â”‚   â”œâ”€â”€ AuthorStats.tsx           # Author analysis
â”‚   â”‚   â”œâ”€â”€ TimeMachine.tsx           # Temporal evolution
â”‚   â”‚   â”œâ”€â”€ CouplingEvidence.tsx      # Commits where pair co-changed
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ clustering/              # Full clustering workspace
â”‚   â”‚   â”‚   â”œâ”€â”€ ClusteringWorkspace.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ClusteringHub.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SnapshotDetail.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ deps/                         # Dependency analysis features
â”‚   â”‚   â”œâ”€â”€ DepsLayout.tsx            # Tab container (Graph, External, Circular)
â”‚   â”‚   â”œâ”€â”€ ImportGraph.tsx           # D3 force graph â€” imports as edges
â”‚   â”‚   â”œâ”€â”€ ExternalPackages.tsx      # Treemap of external deps
â”‚   â”‚   â”œâ”€â”€ CircularDeps.tsx          # Cycle list with path highlighting
â”‚   â”‚   â”œâ”€â”€ FileImportDetail.tsx      # Side panel: what imports what
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ semantic/                     # Semantic domain features
â”‚   â”‚   â”œâ”€â”€ SemanticLayout.tsx        # Tab container (Map, List, Bridges)
â”‚   â”‚   â”œâ”€â”€ DomainMap.tsx             # D3 bubble/pack chart
â”‚   â”‚   â”œâ”€â”€ DomainDetail.tsx          # Files, terms, cross-coupling
â”‚   â”‚   â”œâ”€â”€ DomainList.tsx            # Table view of all domains
â”‚   â”‚   â”œâ”€â”€ BridgeEntities.tsx        # Multi-domain entities
â”‚   â”‚   â”œâ”€â”€ FileSemanticDetail.tsx    # Classification + tokens for a file
â”‚   â”‚   â”œâ”€â”€ DomainBadge.tsx           # Reusable domain tag
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                        # Unified knowledge graph
â”‚   â”‚   â”œâ”€â”€ KnowledgeGraph.tsx        # Main layout: graph + sidebar
â”‚   â”‚   â”œâ”€â”€ GraphCanvas.tsx           # D3 multi-edge renderer
â”‚   â”‚   â”œâ”€â”€ EntityDetail.tsx          # All signals for one entity
â”‚   â”‚   â”œâ”€â”€ PathFinder.tsx            # From â†’ To shortest path
â”‚   â”‚   â”œâ”€â”€ GraphFilters.tsx          # Source type, weight, kind toggles
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ risk/                         # Risk analysis features
â”‚   â”‚   â”œâ”€â”€ RiskLayout.tsx            # Tab container
â”‚   â”‚   â”œâ”€â”€ RiskOverview.tsx          # Scorecard + gauge
â”‚   â”‚   â”œâ”€â”€ RiskTreemap.tsx           # D3 treemap by folder
â”‚   â”‚   â”œâ”€â”€ RiskFileTable.tsx         # Sortable table of risky files
â”‚   â”‚   â”œâ”€â”€ RiskSignalBadge.tsx       # Signal pill component
â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚
â”‚   â””â”€â”€ settings/                     # Per-repo analyzer configuration
â”‚       â”œâ”€â”€ SettingsLayout.tsx
â”‚       â”œâ”€â”€ GitSettings.tsx           # Git analysis config form
â”‚       â”œâ”€â”€ DepsSettings.tsx          # Dependency analysis config form
â”‚       â”œâ”€â”€ SemanticSettings.tsx      # Semantic analysis config form
â”‚       â”œâ”€â”€ AnalyzerRunPanel.tsx      # Run/status controls
â”‚       â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ shared/                           # Reusable UI primitives
â”‚   â”œâ”€â”€ Button.tsx
â”‚   â”œâ”€â”€ Card.tsx
â”‚   â”œâ”€â”€ Modal.tsx
â”‚   â”œâ”€â”€ Badge.tsx
â”‚   â”œâ”€â”€ Tabs.tsx
â”‚   â”œâ”€â”€ Table.tsx
â”‚   â”œâ”€â”€ Tooltip.tsx
â”‚   â”œâ”€â”€ Spinner.tsx
â”‚   â”œâ”€â”€ ErrorBoundary.tsx
â”‚   â”œâ”€â”€ EmptyState.tsx
â”‚   â””â”€â”€ index.ts
â”‚
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useAnalyzerStatus.ts          # Poll analyzer status
â”‚   â”œâ”€â”€ useGraphData.ts               # Fetch + cache graph subsets
â”‚   â”œâ”€â”€ useDebounce.ts
â”‚   â”œâ”€â”€ useLocalStorage.ts
â”‚   â””â”€â”€ useClickOutside.ts
â”‚
â”œâ”€â”€ stores/
â”‚   â”œâ”€â”€ repoStore.ts                  # Current repo context
â”‚   â”œâ”€â”€ filterStore.ts                # Global filters (existing)
â”‚   â””â”€â”€ graphFilterStore.ts           # Graph source/weight filters
â”‚
â”œâ”€â”€ lib/
â”‚   â””â”€â”€ utils.ts                      # cn(), formatters, etc.
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ navigation.ts                 # Tab/route definitions
â”‚
â”œâ”€â”€ design-tokens/
â”‚   â””â”€â”€ ...                           # Theme values
â”‚
â”œâ”€â”€ App.tsx                           # Route definitions
â””â”€â”€ main.tsx                          # Entry point
```

### 6.4 Navigation & UX Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       NAVIGATION STRUCTURE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  TOP BAR (always visible in repo context):                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ â† MyProject â”‚ Dashboard â”‚ Git â–¾ â”‚ Deps â”‚ Semantic â”‚ Graph â”‚    â”‚   â”‚
â”‚  â”‚             â”‚           â”‚       â”‚      â”‚          â”‚       â”‚    â”‚   â”‚
â”‚  â”‚             â”‚           â”‚ Sub:  â”‚      â”‚          â”‚       â”‚    â”‚   â”‚
â”‚  â”‚             â”‚           â”‚ Coupling     â”‚          â”‚       â”‚    â”‚   â”‚
â”‚  â”‚             â”‚           â”‚ Files        â”‚          â”‚ Risk  â”‚    â”‚   â”‚
â”‚  â”‚             â”‚           â”‚ Hotspots     â”‚          â”‚       â”‚    â”‚   â”‚
â”‚  â”‚             â”‚           â”‚ Clustering   â”‚          â”‚ âš™ï¸    â”‚    â”‚   â”‚
â”‚  â”‚             â”‚           â”‚ Timeline     â”‚          â”‚       â”‚    â”‚   â”‚
â”‚  â”‚             â”‚           â”‚ Authors      â”‚          â”‚       â”‚    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  FLOW:                                                                  â”‚
â”‚                                                                         â”‚
â”‚  1. Landing: /repos â†’ pick a repo                                       â”‚
â”‚                                                                         â”‚
â”‚  2. Dashboard: /repos/:id/dashboard                                     â”‚
â”‚     Shows combined view from all analyzers.                             â”‚
â”‚     Cards link to feature-specific views.                               â”‚
â”‚     If analyzer not run â†’ shows "Run Analysis" prompt.                  â”‚
â”‚                                                                         â”‚
â”‚  3. Feature deep-dive: click into any feature tab                       â”‚
â”‚     Each feature is self-contained with its own sub-navigation.         â”‚
â”‚                                                                         â”‚
â”‚  4. Cross-linking:                                                      â”‚
â”‚     - File path (anywhere) â†’ click â†’ /repos/:id/git/files/:path        â”‚
â”‚     - Domain badge â†’ click â†’ /repos/:id/semantic/domains/:id           â”‚
â”‚     - Risk badge â†’ click â†’ /repos/:id/risk (filtered)                  â”‚
â”‚     - "View in graph" â†’ /repos/:id/graph?entity=:id                    â”‚
â”‚     - Entity in graph â†’ sidebar with all signals                        â”‚
â”‚                                                                         â”‚
â”‚  5. Settings: /repos/:id/settings                                       â”‚
â”‚     Configure and run each analyzer independently.                      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.5 Screen Wireframes

#### Dashboard (Combined Intelligence)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â† Back   MyProject   Dashboard  Git â–¾  Deps  Semantic  Graph  Risk âš™ï¸ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  1,240   â”‚ â”‚  8,500   â”‚ â”‚  45      â”‚ â”‚  4       â”‚ â”‚  6.2     â”‚     â”‚
â”‚  â”‚  Files   â”‚ â”‚  Commits â”‚ â”‚  Authors â”‚ â”‚  Domains â”‚ â”‚  Risk/10 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€ Analyzers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  âœ… Git Coupling     2h ago   1,240 files   8,500 edges         â”‚   â”‚
â”‚  â”‚  âœ… Dependencies     2h ago   3,200 imports  45 externals       â”‚   â”‚
â”‚  â”‚  âœ… Semantic          1h ago   4 domains     0.78 coherence     â”‚   â”‚
â”‚  â”‚  âœ… Intelligence      1h ago   risk computed                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€ Top Risks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€ Domains â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ğŸ”´ src/core/engine.py  9.2 â”‚ â”‚  â— Payment    24 files         â”‚   â”‚
â”‚  â”‚  ğŸŸ  src/api/routes.py   7.8 â”‚ â”‚  â— Auth       18 files         â”‚   â”‚
â”‚  â”‚  ğŸŸ  src/models/user.py  7.1 â”‚ â”‚  â— Orders     31 files         â”‚   â”‚
â”‚  â”‚  [View all â†’]                â”‚ â”‚  [View all â†’]                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€ Trends â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  [area chart: commits, coupling, risk over time]                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Knowledge Graph

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Knowledge Graph                                                        â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€ Filters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ [âœ“ Git] [âœ“ Deps] [âœ“ Semantic]   Kind: [All â–¾]   Min: [0.3 â”â—â”]  â”‚â”‚
â”‚  â”‚ ğŸ” [Search entity...                                         ]    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                                     â”‚ ğŸ“„ payment.py                 â”‚â”‚
â”‚  â”‚    D3 graph                         â”‚                               â”‚â”‚
â”‚  â”‚    â”€â”€ blue edges = git coupling     â”‚ Language: python               â”‚â”‚
â”‚  â”‚    â”€â”€ green edges = imports         â”‚ Domain: Payment (0.95)         â”‚â”‚
â”‚  â”‚    â”€â”€ purple edges = similar        â”‚ Risk: ğŸŸ¡ 5.2                  â”‚â”‚
â”‚  â”‚                                     â”‚                               â”‚â”‚
â”‚  â”‚    Nodes colored by domain          â”‚ Relationships:                 â”‚â”‚
â”‚  â”‚    Nodes sized by degree            â”‚  ğŸ”— Co-changes: 8 files       â”‚â”‚
â”‚  â”‚                                     â”‚  ğŸ“¦ Imports: 5                â”‚â”‚
â”‚  â”‚                                     â”‚  ğŸ“¦ Imported by: 3            â”‚â”‚
â”‚  â”‚                                     â”‚  ğŸ·ï¸ Similar: 4                â”‚â”‚
â”‚  â”‚                                     â”‚                               â”‚â”‚
â”‚  â”‚                                     â”‚ Risk signals:                  â”‚â”‚
â”‚  â”‚                                     â”‚  ğŸŸ¡ High fan-out              â”‚â”‚
â”‚  â”‚                                     â”‚  âœ… No circular deps           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                         â”‚
â”‚  Path: [payment.py] â†’ [user.py]  Via: [Any â–¾]  [Find â†’]               â”‚
â”‚  Result: payment.py â†’ order.py â†’ auth.py â†’ user.py (3 hops)           â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Dependencies Explorer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dependencies    [Import Graph]  [External]  [Circular]                â”‚
â”‚                                                                         â”‚
â”‚  Filters: Language [All â–¾]  Direction [Both â–¾]  Min imports [1]        â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚    D3 force graph                                               â”‚   â”‚
â”‚  â”‚    Nodes = files (colored by folder)                            â”‚   â”‚
â”‚  â”‚    Edges = import relationships (directed arrows)               â”‚   â”‚
â”‚  â”‚    Red highlighted = files in circular dependencies             â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚    Click node â†’ detail panel below                              â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€ src/services/payment.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Imports (5):                     Imported by (3):               â”‚   â”‚
â”‚  â”‚  â”œâ”€ src/models/order.py           â”œâ”€ src/api/routes.py          â”‚   â”‚
â”‚  â”‚  â”œâ”€ src/models/invoice.py         â”œâ”€ src/workers/billing.py     â”‚   â”‚
â”‚  â”‚  â”œâ”€ src/utils/validators.py       â””â”€ tests/test_payment.py      â”‚   â”‚
â”‚  â”‚  â”œâ”€ stripe (external)                                           â”‚   â”‚
â”‚  â”‚  â””â”€ logging (stdlib)                                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Semantic Domain Map

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Semantic Domains    [Map]  [List]  [Bridges]                          â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚    D3 bubble chart                                              â”‚   â”‚
â”‚  â”‚    Each bubble = domain (sized by file count)                   â”‚   â”‚
â”‚  â”‚    Lines between bubbles = cross-domain coupling                â”‚   â”‚
â”‚  â”‚    Colors = domain identity                                     â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚   â”‚
â”‚  â”‚    â”‚ Payment  â”‚â”€â”€â”€â”€â”€â”€â”                                          â”‚   â”‚
â”‚  â”‚    â”‚  24 filesâ”‚      â”‚ cross-coupling                           â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â–¼                                          â”‚   â”‚
â”‚  â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚   â”‚
â”‚  â”‚              â”‚   Orders     â”‚â”€â”€â”€â”€â”‚  Auth  â”‚                     â”‚   â”‚
â”‚  â”‚              â”‚   31 files   â”‚    â”‚18 filesâ”‚                     â”‚   â”‚
â”‚  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚   â”‚
â”‚  â”‚                                                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  Click a domain to see detail: files, top terms, coherence, bridges    â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Risk Map

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Risk Map    [Overview]  [Files]  [Folders]                            â”‚
â”‚                                                                         â”‚
â”‚  Risk Score: 6.2 / 10  â”â”â”â”â”â”â”â”â”â”â”â”â—â”â”â”â”â”â”â”â”â”                         â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ ğŸ”— 5.8  â”‚ â”‚ ğŸ“¦ 7.1  â”‚ â”‚ ğŸ”¥ 4.5  â”‚ â”‚ ğŸ·ï¸ 6.0  â”‚                      â”‚
â”‚  â”‚Coupling â”‚ â”‚Dep Risk â”‚ â”‚  Churn  â”‚ â”‚Semantic â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                                                                         â”‚
â”‚  â”Œâ”€ Treemap (folders by risk) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚  src/core (ğŸ”´)   â”‚ src/api (ğŸŸ )   â”‚  src/models (ğŸŸ¢)     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  risk: 8.1       â”‚ risk: 6.5      â”‚  risk: 3.2           â”‚   â”‚   â”‚
â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚ src/services(ğŸŸ ) â”‚ src/utils (ğŸŸ¡) â”‚                      â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  File                    Risk   Signals                                 â”‚
â”‚  src/core/engine.py      9.2    ğŸ”— High coupling | ğŸ“¦ Circular dep     â”‚
â”‚  src/api/routes.py       7.8    ğŸ”¥ High churn | ğŸ·ï¸ 3 domains           â”‚
â”‚  src/models/user.py      7.1    ğŸ“¦ High fan-out | ğŸ”— God class         â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          COMPLETE DATA FLOW                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  1. USER creates repo via Frontend                                          â”‚
â”‚     Frontend â†’ POST /repos â†’ Orchestrator creates repo dir + empty DB       â”‚
â”‚                                                                             â”‚
â”‚  2. USER triggers analyzers (one or all)                                    â”‚
â”‚     Frontend â†’ POST /repos/{id}/analyzers/git/run                           â”‚
â”‚     Orchestrator â†’ creates task row â†’ calls git_analyzer.analyze(task)      â”‚
â”‚     Git analyzer: mirror â†’ extract â†’ edges â†’ writes to shared DB            â”‚
â”‚     Task status updated: running â†’ completed                                â”‚
â”‚                                                                             â”‚
â”‚     Frontend â†’ POST /repos/{id}/analyzers/deps/run                          â”‚
â”‚     Orchestrator â†’ creates task â†’ calls dep_analyzer.analyze(task)          â”‚
â”‚     Dep analyzer: parse imports â†’ writes entities + relationships to DB     â”‚
â”‚                                                                             â”‚
â”‚     Frontend â†’ POST /repos/{id}/analyzers/semantic/run                      â”‚
â”‚     Orchestrator â†’ creates task â†’ calls semantic_analyzer.analyze(task)     â”‚
â”‚     Sem analyzer: tokenize â†’ TF-IDF â†’ cluster â†’ writes to DB               â”‚
â”‚                                                                             â”‚
â”‚     Frontend â†’ POST /repos/{id}/analyzers/intelligence/run                  â”‚
â”‚     Orchestrator â†’ creates task â†’ calls project_intel.analyze(task)         â”‚
â”‚     Intelligence: reads all data â†’ computes risk â†’ writes scores            â”‚
â”‚                                                                             â”‚
â”‚  3. USER explores data via Frontend                                         â”‚
â”‚     Frontend â†’ GET /repos/{id}/git/coupling?path=... â†’ Orchestrator         â”‚
â”‚     Orchestrator â†’ registry.get_git_api().get_coupling(db_path, ...) â†’      â”‚
â”‚     Git analyzer API impl â†’ queries git_edges table â†’ returns JSON          â”‚
â”‚                                                                             â”‚
â”‚     Frontend â†’ GET /repos/{id}/graph/neighbors/42 â†’ Orchestrator            â”‚
â”‚     Orchestrator â†’ builds NetworkX graph from relationships table â†’         â”‚
â”‚     Returns subgraph as JSON                                                â”‚
â”‚                                                                             â”‚
â”‚     Frontend â†’ GET /repos/{id}/risk/overview â†’ Orchestrator                 â”‚
â”‚     Orchestrator â†’ registry.get_api("intelligence").get_risk(...) â†’         â”‚
â”‚     Intelligence API â†’ queries intel_risk_scores â†’ returns JSON             â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8. What Moves Where (Migration Map)

Current `lfca/` module â†’ new project locations:

| Current File | New Location | Notes |
|---|---|---|
| `lfca/api.py` | Split â†’ `platform/code_intel/routers/*.py` | Each endpoint group becomes a router |
| `lfca/storage.py` | Split â†’ `platform/code_intel/storage.py` (shared) + `git_analyzer/api.py` (git queries) | Storage factory stays in platform; query logic moves to analyzer |
| `lfca/schema.py` | â†’ `platform/code_intel/schema.py` | Unified schema owned by platform |
| `lfca/config.py` | Split â†’ `platform/code_intel/config.py` (RepoPaths) + `git_analyzer/config.py` (CouplingConfig) | |
| `lfca/extract.py` | â†’ `git_analyzer/extract.py` | |
| `lfca/edges.py` | â†’ `git_analyzer/edges.py` | |
| `lfca/changesets.py` | â†’ `git_analyzer/changesets.py` | |
| `lfca/git.py` | â†’ `git_analyzer/git.py` | |
| `lfca/mirror.py` | â†’ `git_analyzer/mirror.py` | |
| `lfca/sync.py` | â†’ `git_analyzer/sync.py` | |
| `lfca/runner.py` | â†’ `platform/code_intel/orchestrator.py` (task dispatch) + `git_analyzer/plugin.py` (git pipeline) | |
| `lfca/clustering/` | â†’ `git_analyzer/clustering/` | Clustering is git-specific for now |
| `lfca/logging_utils.py` | â†’ `platform/code_intel/logging_utils.py` | Shared utility |
| `frontend/src/api.ts` | Split â†’ `frontend/src/api/*.ts` | One file per router |
| `frontend/src/components/` | â†’ `frontend/src/features/` | Reorganized by feature |

---

## 9. Implementation Roadmap

### Phase 1: Project Scaffolding & Split (2-3 weeks)

| Task | Effort | Notes |
|------|--------|-------|
| Create monorepo structure (platform/, git-analyzer/, frontend/) | 1d | pyproject.toml for each |
| Define interfaces (analyzer.py, git_analyzer.py, types.py) | 2d | The critical design step |
| Implement platform schema.py (unified DB) | 1d | |
| Implement registry + orchestrator | 1d | |
| Move git code to git-analyzer/ | 2d | Mechanical move + adapt imports |
| Implement GitPlugin + GitAPI | 3d | Wrap existing logic behind interfaces |
| Implement platform routers (proxy layer) | 2d | 1-1 mapping from old api.py |
| Verify all existing features work | 2d | End-to-end testing |

### Phase 2: Dependency Analyzer (2-3 weeks)

| Task | Effort | Notes |
|------|--------|-------|
| Define DepAnalyzerAPI interface | 1d | |
| Python import parser (ast module) | 2d | |
| TypeScript import parser (regex) | 2d | |
| DepPlugin + DepAPI implementation | 2d | |
| Platform router: deps.py | 1d | |
| Frontend: DepsLayout + ImportGraph + CircularDeps | 4d | |
| Tests | 2d | |

### Phase 3: Semantic Analyzer (3-4 weeks)

| Task | Effort | Notes |
|------|--------|-------|
| Define SemanticAnalyzerAPI interface | 1d | |
| Token extraction (tree-sitter / AST) | 3d | |
| TF-IDF + cosine similarity | 2d | |
| Domain clustering + labeling | 2d | |
| SemanticPlugin + SemanticAPI | 2d | |
| Platform router: semantic.py | 1d | |
| Frontend: SemanticLayout + DomainMap + DomainDetail | 4d | |
| Tests | 2d | |

### Phase 4: Intelligence & Unified Views (2-3 weeks)

| Task | Effort | Notes |
|------|--------|-------|
| project-intelligence: risk model | 2d | |
| project-intelligence: cross-coupling correlations | 2d | |
| Platform: graph router (NetworkX queries) | 2d | |
| Platform: intelligence + risk routers | 1d | |
| Frontend: KnowledgeGraph explorer | 4d | |
| Frontend: RiskMap + RiskTreemap | 3d | |
| Frontend: Combined Dashboard | 2d | |
| Tests | 2d | |

### Phase 5: Polish & Extend (ongoing)

- C#/Java parsers
- Ownership analyzer (extract from git author data)
- Complexity analyzer (cyclomatic complexity)
- Architecture map visualization
- Export to Excalidraw
- CLI for headless analysis

---

## 10. Technology Decisions

| Decision | Chosen | Rationale | Migration Path |
|----------|--------|-----------|---------------|
| Project structure | Python packages in monorepo | Simple, shared venv, `pip install -e .` | Extract to separate repos + PyPI if team grows |
| Inter-project comms | Direct Python calls | Zero overhead, type-safe | Add HTTP/gRPC if deployed as microservices |
| Database | SQLite (one per repo) | Zero-ops, fast, proven | Migrate to PostgreSQL if multi-user/concurrent |
| Graph queries | NetworkX in-memory | Fast for <100K nodes, Python-native | Swap to Neo4j/Memgraph for large graphs |
| Async tasks | FastAPI BackgroundTasks | Already works, simple | Add Celery/ARQ for multi-worker |
| Caching | Python lru_cache | Single process | Add Redis for multi-process |
| AST parsing | tree-sitter (+ ast for Python) | Multi-language, well-maintained | â€” |
| Semantic embedding | TF-IDF + cosine similarity | Fast, no GPU, interpretable | Add CodeBERT for higher accuracy |
| Frontend framework | React + Vite + TailwindCSS | Already in use, proven | â€” |
| Visualization | D3.js | Already in use, flexible | â€” |
| State management | React state + Zustand | Lightweight | â€” |

---

## 11. Extensibility Guide

### Adding a New Analyzer

1. **Create project**: `my-analyzer/` with `pyproject.toml` + `my_analyzer/` package
2. **Define interface**: Add `MyAnalyzerAPI(ABC)` in `platform/code_intel/interfaces/my_analyzer.py`
3. **Implement plugin**: `my_analyzer/plugin.py` â†’ subclass `BaseAnalyzer` + implement `MyAnalyzerAPI`
4. **Register**: Add import to `platform/code_intel/app.py` â†’ `register_analyzers()`
5. **Add router**: `platform/code_intel/routers/my.py` â†’ proxy to `MyAnalyzerAPI`
6. **Add frontend**: `frontend/src/features/my/` + `frontend/src/api/my.ts`
7. **The orchestrator, graph queries, and risk model automatically pick up new relationships**

### Adding a New Language Parser (within dep-analyzer or semantic-analyzer)

1. Create `dep_analyzer/parsers/my_language_parser.py`
2. Subclass `BaseParser`, implement `parse_imports()`, `parse_entities()`
3. Register by file extension in parser factory
4. Both analyzers automatically use it

### Adding a New Relationship Type

1. Add constant to `RelKind` in `code_intel/interfaces/types.py`
2. Write relationships with the new kind from your analyzer
3. Knowledge graph, risk model, and graph queries automatically include it
4. Add filtering option in `GraphFilters.tsx` frontend component
